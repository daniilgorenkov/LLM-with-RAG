## Mälardalen University School of Innovation Design and Engineering Västerås, Sweden Thesis for the Degree of Bachelor of Science in Computer Science 15. credits# PREDICTIVE MAINTENANCE FOR FREIGHT TRAINS: A MACHINE LEARNING APPROACH TO OPTIMIZING WHEEL REPLACEMENT SCHEDULES## Max Strangdisruptions. Green Cargo, a major rail freight provider, currently replaces train wheels based on
scheduled maintenance or reactive repairs, leading to inefficiencies. This thesis explores the application of machine learning to predictive maintenance by analyzing sensor data from DPC detectors
mounted along railway tracks. These detectors measure force impacts as the train moves, providingUsing supervised learning techniques and grid search optimization, predictive models for left and right wheel damage were developed and evaluated. The left wheel model achieved a test R2
of 1.0000 with an RMSE of 0. kilonewton, while the right wheel model achieved a test R2 of
0.9873 with an RMSE of 0. kilonewton. Forecasting trends over a three-year horizon identified
one axle requiring replacement, with left wheels typically failing first. Maintenance scheduling logic was implemented to replace both wheels on an axle when either exceeded predefined thresholds.data from DPC detectors. Future work will focus on integrating real-time monitoring and refining## 1. Introductiontransport systems. In particular, optimizing the maintenance of critical components, such as train wheels, is essential for minimizing operational disruptions, reducing costs, and enhancing safety.
However, one of the key challenges in railway operations is determining the optimal time to replace train wheels, a decision that has traditionally relied on fixed schedules or reactive measures. This
often leads to either early replacements, which increase operational costs, or delayed replacements,Green Cargo, one of Sweden’s leading rail freight companies, operates a large and diverse fleet of trains across various routes with different operational conditions and braking systems.
These variations lead to differences in wear patterns, which complicate the decision-making process regarding wheel replacement. The traditional approach of using fixed maintenance schedules does
not account for these variations, presenting an opportunity for more adaptive and data-drivenCurrently, Green Cargo employs a threshold-based monitoring system for wheel maintenance using sensor data from Dynamic Pressure Check (DPC) detectors installed by Trafikverket .
system. When a value exceeds a certain limit, an alarm is triggered, prompting the maintenance team to schedule maintenance. While this system successfully prevents catastrophic failures, it
operates purely reactively, providing alerts only after predefined thresholds have been exceeded.
needs, limiting their ability to optimize maintenance scheduling and resource allocation.The limitations of threshold-based approaches become particularly apparent in operational planning and cost management. The inability to predict when wheels will require maintenance
means that all maintenance actions are triggered reactively, often resulting in expensive emergency interventions. These unplanned maintenance events are significantly more costly than scheduled
activities, as they involve potential service delays, overtime labor, and urgent resource allocation.
Furthermore, the current approach provides no insights into wheel degradation patterns or trends that might help predict future maintenance needs, representing a missed opportunity for proactiveThis thesis addresses these limitations by exploring the application of machine learning techniques to predict wheel replacement needs before they become critical. By analyzing historical
sensor data from DPC detectors, this study aims to develop predictive models that can forecast
when wheel maintenance will be required well in advance of threshold exceedance. Such an approach could enable Green Cargo to transition from reactive to truly predictive maintenance ,
allowing for better resource planning, cost optimization, and operational efficiency.This study focuses specifically on three Transmontana series locomotives (M4004, M4008,
M4016) operating on the Borlänge-Boden route. This route was selected due to its unique operational characteristics, particularly the use of metal-against-metal brake systems that create more
pronounced wheel wear patterns compared to modern brake technologies used on other routes.
This increased wear provides richer data signals for machine learning analysis, making this route an ideal test case for developing predictive maintenance models. Although the study examines only
three locomotives, these units are representative of a broader population of 20 similar locomotives operating on the same route with identical brake systems and operational characteristics. The insights gained from this analysis can potentially be generalized to the entire fleet of similar locomotives and their associated wagons, providing a foundation for broader predictive maintenancePrevious research has demonstrated the effectiveness of predictive maintenance in various industries , including specific applications to railway systems , . However, most existing
the unique operational conditions of rail freight, such as varying braking systems and loading conditions. Additionally, while threshold-based monitoring is common in the industry, the transitionof predicting optimal wheel replacement timing using sensor data from DPC detectors. Specifically,patterns in force measurement data that can indicate the need for wheel maintenance. While realtime validation of predictions has not been conducted due to time constraints, the developed models was evaluated on historical data, allowing for a robust assessment of their predictive performance.in rail freight operations, potentially reducing costs, minimizing unplanned downtime, and enhancing the safety and efficiency of rail transport. By providing a detailed evaluation of predictive
maintenance models tailored to the specific needs of Green Cargo, this research offers valuable train components. The methodology developed in this study could also serve as a foundation for
expanding predictive maintenance applications to other railway components beyond wheels.The remainder of this thesis is structured as follows: Chapter 2 provides background information on predictive maintenance, locomotive systems, and DPC detector technologies. Chapter 3 reviews
related work in railway predictive maintenance and machine learning applications. Chapter 4
formulates the research problem and specific objectives. Chapter 5 describes the methodology used for data collection, preprocessing, and model development. Chapter 6 discusses ethical and societal
considerations. Chapter 7 presents the experimental setup and implementation details. Chapter
8 reports the results of the predictive models’ performance. Chapter 9 discusses the implications
and limitations of the findings. Finally, Chapter 10 provides conclusions and suggestions for future## 2. BackgroundPredictive Maintenance (PdM), described in Mobley , is a maintenance strategy that uses datadriven techniques to anticipate equipment failures, allowing maintenance to be scheduled proactively before breakdowns occur. Unlike traditional corrective maintenance (performed after a
failure) or preventive maintenance (performed on fixed schedules), PdM uses real-time condition monitoring to guide decisions, minimizing unnecessary interventions and costly disruptions.The locomotives studied in this project are the Transmontana series, manufactured by Softronic
and referred to as "MB" in the Green Cargo fleet . These locomotives are six-axle
Transmontana locomotives are equipped with modern electric traction systems that provide efficient power delivery and robust hauling capacity. However, their braking systems use a "metalagainst-metal" mechanism, which causes significant wear and tear on the wheels. This characteristic makes these locomotives particularly suitable for studying predictive maintenance as it
generates substantial wear and tear data, offering a rich dataset for modeling and analysis. The pronounced wear provides clear signals of degradation, making it easier to identify patterns andTrafikverket, the Swedish Transport Administration, has deployed various types of Dynamic Pressure Check (DPC) detectors across the railway network to monitor the condition of train components, including wheels .Figure 2 shows a map of the detector locations across Sweden. Each detector type is markedwith a unique color, making it possible to distinguish between them. The PHOENIX MDS WILD detectors, which are marked in blue and the Schenck detectors marked in green, are the types
investigated in this study. While the map covers the entire country, it is possible to visually identify the detectors located along the Borlänge – Boden route, the railway section chosen for this study. The route was selected for two primary reasons. Firstly, it offers access to data from both PHOENIX and Schenck detectors, enabling a comprehensive analysis. Secondly, the locomotives
operating on this route use older brake systems, as described in Section 2.2. These brake systems involve significant metal-on-metal contact during braking, contributing to increased wear and tear,
which makes this route particularly relevant for studying predictive maintenance.ÖxneredÄlvsborgsbananSkövde StångådalsbananSödrastambananLinköpingFiskebyFigure 3 provides a close-up view of the actual DPC detectors embedded in the railway tracks.they pass over them. The image highlights their physical integration into the track infrastructure,
illustrating the robust design required to endure constant exposure to heavy loads and environmental conditions.- Wheel-Damage Detectors These detectors are crucial in identifying potential damage tothe wheels as trains pass over them. There are two main types of wheel-damage detectors used- PHOENIX MDS WILD Detectors: Six of these detectors are installed at specificlocations along the tracks. These sensors measure the dynamic forces exerted by the- Schenck Detectors: Twenty-five Schenck detectors are spread across the railway sys
tem. Like the PHOENIX detectors, these sensors capture the dynamic pressure dataThese detectors are responsible for measuring and collecting data, but they do not process or analyze it. The data collected by the detectors is provided to the customers (such as Green
Cargo), who use their own software tools to analyze the data and identify potential issues, such asFor each wheel passage over a detector, the DPC system records comprehensive data for both wheels on the axle, as shown in Table 1. This information provides the foundation for analyzingHowever, there are limitations in the detection system. Since the wheels are conically shaped and oscillate as the trains move along the track, a damaged portion of the wheel might not always
come into direct contact with the detector. This means that potential damage may go undetected if the wheel’s damaged area is not aligned with the sensor at the time the train passes over it.This conical shape significantly affects how DPC detectors collect sensor data. As shown in Figure 4, only a narrow section of each wheel’s surface contacts the rail during operation. This1. Limited Contact Area: Since only part of the wheel touches the detector, localized damageor wear may not be detected if it occurs on portions of the wheel that don’t make regular2. Force Measurement Patterns: The concentrated contact creates specific force patterns inthe sensor readings. A well-maintained wheel produces consistent force values, while damaged wheels create irregular patterns as different surface conditions pass over the detectors.3. Multiple Measurements Needed: Because wheel damage might not always align with thesensor during a single pass, analyzing patterns across multiple detector encounters becomesIn rail freight operations, PdM has significant potential to optimize performance, safety, and costefficieny. Green Cargo, a leading Swedish logistics company specializing in rail freight, operates a
diverse fleet of cargo trains where wheels being critical components, undergo significant wear due
to continuous loading, friction, and track impacts. Currently, decisions regarding wheel replacements are drawn from three main strategies: Run to Failure (R2F), Scheduled Maintenance, and- Run to Failure (R2F): is a maintenance strategy where components like wheels are allowedto fail before replacement occurs. While this may save on upfront maintenance costs, it is highly risky and costly, as it leads to unscheduled downtimes and requires emergency
maintenance when a failure occurs, often in the middle of a track operation, as described in- Scheduled Maintenance/Preventive Maintenance: on the other hand, involves repla cing components at fixed intervals. While it helps avoid the extreme costs of R2F, it alsocarries the risk of premature replacement, which results in unnecessary costs. Additionally,
scheduled maintenance can be delayed, increasing the risk of encountering an R2F scenario,- Threshold-Based Predictive Maintenance leverages data from the DPC detectors, wherepredefined thresholds are set for specific sensor values. When these thresholds are exceeded,
an alarm is triggered, prompting the scheduling of maintenance. As established by Trafikverket and detailed in wheel-rail impact studies , specific threshold limits have been set for locomotive wheel peak force measurements, as shown in Table 2. These peak force values represent the maximum impact force recorded when a wheel passes over the DPC detector.
When wheels develop damage such as flat spots, cracks, or irregular wear, these damaged areas create significantly higher impact forces upon contact with the rail compared to smooth,The "high" alarm is triggered at 425 kilonewton, requiring immediate attention, while a
"warning" alarm occurs at 350 kilonewton, allowing continued operation with speed restrictions to the final destination where certified staff should inspect the locomotive. These type, track segment, or operating company. They are designed to detect wheel conditions that create abnormally high peak force impacts during wheel passage, such as wheel flats,
cracks, or surface irregularities that generate force spikes significantly above the averageWhile these regulatory limits apply to all operators, individual companies like Green CargoThis threshold-based system has been and still is, a valuable tool for Green Cargo in planning maintenance activities. However, it does not fully utilize the potential of predictive analytics. It only responds to exceedances of predefined limits, rather than forecasting when failures are likely to occur. This limitation means that the current system is more reactive than predictive.Machine learning (ML), a subfield of artificial intelligence, offers powerful tools to process and learn from large datasets . In the field of predictive maintenance (PdM), ML models uncover
patterns in sensor data, enabling organizations to predict equipment failures with greater accuracy
and optimize maintenance schedules , . This capability minimizes unplanned downtime,capture operational data such as temperature, pressure, vibration, and usage metrics. This data forms the foundation for machine learning models, which can identify patterns that signal wear,
degradation or failure. Rather than relying on traditional scheduled or reactive maintenance, PdM
powered by ML can anticipate failures before they occur, resulting in more efficient and costeffective operations.Machine learning approaches for PdM generally fall into two main categories: Supervised learning and Unsupervised learning. These methods differ fundamentally in their interaction with- Supervised Learning: In supervised learning, models are trained on historical datasetswhere input features (e.g., sensor readings) are labeled with corresponding outcomes (e.g.,
failure events, time-to-failure, or continuous damage levels). This makes it suitable for tasks such as predicting the remaining useful life (RUL) of components, forecasting continuous
degradation progression, or classifying fault types. By learning direct relationships between
inputs and outputs, supervised models excel in scenarios with abundant labeled data. For example, a supervised learning algorithm might predict the RUL of a pump based on vibration,- Unsupervised Learning: Unsupervised learning operates on unlabeled data, identifyinghidden structures or patterns within it. This makes it valuable for detecting anomalies that
may signal emerging issues or clustering similar failure modes for deeper analysis. Unsupervised learning can be useful when labeled data is scarce or when equipment behavior
deviates from historical norms. For instance, anomaly detection might reveal unexpected behavior in a motor’s performance that precedes a failure, even if no previous failures haveThe choice of ML approach often depends on factors such as the availability of labeled data, the specific objectives of the maintenance strategy and the nature of the equipment being monitored.
This study explores both categories by utilizing linear regression for trend analysis, XGBoostfor regression-based damage prediction, and Isolation Forest for unsupervised anomaly detection. These methods exemplify the breadth and versatility of ML in predictive maintenance.- Adaptability: Models can be tailored to a wide variety of equipment types and operating- Scalability: Machine learning models can process vast amounts of data from multiple sensorsacross different systems, making them highly scalable in large industrial settings.- Efficiency: By predicting failures early, ML models enable more targeted maintenance,- Cost-Effectiveness: Accurate failure predictions reduce the need for expensive, unnecessaryrepairs and replacements, ensuring maintenance is only conducted when truly needed.Additionally, advancements in cloud computing and IoT (Internet of Things) technologies have made it easier to deploy and scale machine learning models for predictive maintenance, furtherrelationships between input features and continuous target variables. The method estimates theWhere y represents the dependent variable, xi are the independent variables, β0 is the intercept,βi are the slope coefficients representing the rate of change, and ϵ is the error term.Linear regression uses the ordinary least squares method to minimize the sum of squared residuals, providing optimal parameter estimates under certain assumptions. The method excels inLinear regression was selected for long–term forecasting because wheel damage follows approximately linear degradation trends over time, providing stable 3–year predictions. Kang et al.
study, noting it showed regular degradation patterns suitable for trend fitting . It also servessequentially, combining multiple weak learners (typically decision trees) to improve prediction accuracy. Each tree in the sequence is trained to correct the erroiteratively minimizes a loss function to optimize predictions [rs o21].f its predecessors and the process- L(yi, yi): Loss function (e.g., mean squared error for regression or log loss for classification).- Ω(f): Regularization term that penalizes model complexity (e.g., tree depth or number of- Loss Function: Includes both the gradient and second-order derivative (Hessian) for moreWhere hi is the Hessian (second derivative of the loss function) and w represents leaf weights.- Regularization: Adds an L1 or L2-norm penalty to control tree complexity:Where T is the number of leaves, and λ controls the regularization strength.XGBoost was chosen because it excels with mixed tabular data, handles non-linear relationships
between wheel damage factors, provides interpretable feature importance scores essential for Research Question 2, and includes built-in regularization to prevent overfitting. XGBoost has proven
effective for regression–based damage prediction in predictive maintenance, successfully preventingIsolation Forest is an unsupervised algorithm specifically designed for anomaly detection. It isolates anomalies by constructing random decision trees that partition the data. Key characteristics- Random Partitioning: Decision trees are created by recursively splitting the data based- Path Length: Anomalies require fewer splits to isolate due to their sparsity in the feature- Anomaly Score: An anomaly score is computed for each data point based on the averageIsolation Forest excels in detecting rare or unexpected faults in complex, high-dimensional datasets and does not require labeled data, making it ideal for scenarios where anomalies are infrequent orlearned during training. Unlike model parameters (such as weights in neural networks), hyperparameters control the learning process and model complexity .hyperparameters within predefined ranges. Combined with cross-validation, grid search provides robust hyperparameter selection by evaluating each configuration’s performance across multiple
data partitions, ensuring optimal model performance while preventing overfitting to specific dataWorking with sensor data introduces challenges such as missing values, outliers, and noisy signals.
Pre–processing techniques, such as normalization, are essential for ensuring data quality. Feature engineering, where raw data is transformed into meaningful input features, also plays a crucial
role in improving model performance. This process involves creating new variables from existing
measurements, such as calculating damage indicators from peak and mean force values, implementing rolling statistics to capture temporal patterns, and encoding categorical variables for machine
learning algorithms . Effective feature engineering can significantly enhance model performance by providing algorithms with more informative representations of the underlying physical processes.Another significant challenge in predictive maintenance is the limited availability of actual failure data for model validation. Unlike controlled laboratory experiments, real–world industrial
systems rarely run to complete failure, making it difficult to validate predictions against confirmed
failure events. This challenge is particularly pronounced in safety–critical applications where equipment is replaced preemptively based on threshold exceedance rather than actual failure occurrence.The temporal nature of degradation presents additional complexity, as damage progression patterns may vary significantly between individual assets due to operational differences, environmental
conditions, and maintenance history. Long–term forecasting compounds these challenges, as modelEvaluating the effectiveness of machine learning models in regression–based predictive maintenance requires metrics that assess continuous prediction accuracy rather than discrete classification
performance. Metrics such as coefficient of determination (R2), Root Mean Square Error (RMSE), and Mean Absolute Error (MAE) are particularly valuable for understanding model performance in predicting continuous damage progression and threshold exceedance timing.regression metrics that assess the accuracy of continuous damage level predictions. In this study,
the following evaluation metrics are employed to assess the models’ ability to predict wheel damage- Coefficient of Determination (R2): Measures the proportion of variance in the targetvariable that is predictable from the input features, providing a scale-independent assessmentWhere yi represents actual values, yi represents predicted values, and ¯y is the mean of actual- Root Mean Square Error (RMSE): Measures the average magnitude of prediction errorsin the same units as the target variable (kN), providing interpretable accuracy assessmentLower RMSE values indicate better prediction accuracy, with values closer to zero representing perfect predictions.- Mean Absolute Error (MAE): Calculates the average absolute difference between pre
dicted and actual values, providing a robust measure less sensitive to outliers :MAE provides intuitive interpretation of average prediction deviation in kN units.- Cross-Validation: Cross–validation is a statistical method used to assess model perform
ance and generalization capability by partitioning data into multiple subsets. In k–fold cross–
validation, the dataset is divided into k equal parts, where k-1 parts are used for training and one part for validation, with this process repeated k times to ensure each subset serves
as validation data once . This technique provides more robust performance estimates
than simple train–test splits and helps detect overfitting by evaluating model stability across
different data partitions. 5–fold cross–validation R² scores assess model stability and generalization capability across different data subsets, ensuring robust hyperparameter selectionThese regression metrics enable comprehensive evaluation of the model’s ability to accurately predict continuous wheel damage values, essential for precise maintenance scheduling and thresholdaround predictions and enable risk–informed decision making. Monte Carlo simulation is a computational technique that uses repeated random sampling to model uncertainty propagation andIn predictive maintenance applications, Monte Carlo methods enable the quantification of prediction uncertainty by incorporating variability in model parameters, input features, and degradation processes. By running multiple simulations with randomly sampled variations, the technique
produces probability distributions of future equipment conditions, providing decision makers with
both point estimates and confidence intervals for maintenance planning.## 3. Related WorkDoshi and Shah conducted a comparative study of machine learning techniques for predictive maintenance in industrial systems, evaluating multiple algorithms including Isolation Forest and
XGBoost for anomaly detection and fault prediction. Isolation Forest achieved 86.5% precision for anomaly detection, while XGBoost achieved 93.5% accuracy for fault classification. Their study
highlighted the effectiveness of these algorithms for processing high-dimensional sensor data inThe relevance of this research lies in its validation of Isolation Forest and XGBoost for predictive maintenance, though their application differs from the current study: while Doshi and Shah applied XGBoost for fault classification, this study employs XGBoost for regression-based damage level prediction. Their findings provide foundational support for the algorithm selection in railwayMcKinnon et al. applied Isolation Forest to monitor wind turbine pitch systems using SCADA
data, focusing on detecting anomalies that could indicate impending failures. Their study demonstrated that Isolation Forest effectively identified anomalies months before failures occurred, achieving a precision of 85%. This early detection capability was critical for minimizing maintenance
costs and operational downtime. The approach taken by McKinnon et al. is relevant to this thesisMajidiparast et al. present a prescriptive analytics framework for optimal intelligent predictive maintenance of railway tracks. The study utilizes Graph Convolutional Networks (GCNs)
to analyze spatial and temporal data collected from railway systems, including geometric measurements and historical maintenance records. The model effectively predicts potential track failures before their occurrence, aiming to reduce downtime and extend the lifespan of railway assets. A significant contribution of this research is the modeling of the railway network as a bipartite graph,
capturing the relationships between different segments of the railway infrastructure. This approach allows the GCN to efficiently propagate information across the network, enhancing the prediction
accuracy for maintenance needs. The study reports a high level of effectiveness in its computational experiments, demonstrating the practical applicability of advanced machine learning techniques in railway maintenance. While this study focuses on track infrastructure, its methodology offers valuable insights for predictive maintenance in other components of railway systems, such as locomotive
wheels. The use of GCNs to model spatial relationships and predict maintenance needs can inform
approaches that analyze RFID sensor data for wheel maintenance. Incorporating similar graphbased modeling techniques could enhance the accuracy and efficiency of predictive maintenanceYang and Létourneau developed a methodology to predict train wheel failures using operational
and maintenance data from the railway industry. They addressed critical challenges including automatic labeling, feature extraction, and model building, achieving a 97% prediction rate of wheel failures while maintaining a reasonable false alert rate of 8%. Their approach yielded promising results in large-scale experiments, demonstrating significant potential for predictive maintenance
in railways. The study successfully utilized Wheel Impact Load Detector data, showing that even with a focused data source, effective prediction models can be developed when the right machine
learning techniques are applied. Their work established an important foundation for sensor-basedDaniyan et al. implemented artificial intelligence techniques for predicting wheel bearing failures in railcar learning factories. Their research utilized temperature data to monitor bearing
degradation, establishing prediction models with continuous usage patterns over 480 days. The study achieved high prediction accuracy with R-values closer to 1, successfully identifying potential
failure periods for wheel bearings, with first signs of degradation appearing after approximately
330 days of operation. While the approach demonstrated good practical value for maintenance
planning, it was constrained by its focus on temperature as the sole degradation indicator, potenShangguan and Xie addressed the challenge of limited wheel degradation samples by developing a time series generator adversarial network (TimeGAN) to generate synthetic wheel degradation
data. Their innovative approach used a sliding window technique to expand the input dataset and
incorporated a stationary gamma process to improve generated data quality. The research demonstrated effective prediction of wheel diameter wear using the Gated Recurrent Unit (GRU) network
with high accuracy. Though advanced in its methodology, the study’s reliance on synthetic data introduces questions about how well the models would translate to varied real-world conditions.Theissler et al. surveyed the use of machine learning for predictive maintenance in the automotive industry, examining various applications including engine, battery, and transmission systems.
They evaluated different ML techniques across these domains, finding Support Vector Regression
particularly effective for predicting remaining useful life of components. Their comprehensive review highlighted application patterns and common challenges. The work provides valuable insights anomaly detection and prediction tasks. While thorough in classification of approaches, they notedLe-Nguyen studied real-time learning approaches for predictive maintenance of railway systems,
developing a pipeline employing online machine learning to address the challenges of fast-paced data streams. Their implementation demonstrated the potential of online learning for automated data preprocessing in railway maintenance. The research showed promising results for real-time application, though full integration with existing maintenance protocols presented ongoing challenges.Wang et al. proposed a novel transformer-based framework with multiplex local-global temporal fusion (LGF-Trans) for high-speed train wheel wear prediction utilizing vibration signals.
Their methodology combined attention mechanisms with both local and global temporal information to accurately predict wheel wear curves. The experimental results using real operational data from high-speed trains demonstrated superior performance compared to other deep learning methods. However, the complexity of the transformer architecture requires significant computationalfor predictive maintenance in Industry 4.0, analyzing articles published between 2015 and 2020.
Their review identified key frameworks, architectures, and tools in predictive maintenance, classifying research into integration issues, big data analysis, machine learning approaches, and reasoning
with ontologies. This comprehensive analysis provided valuable context on the state-of-the-art and challenges in the field, but highlighted the need for more research on predictive maintenanceKang et al. developed a machine learning-based approach for predicting the remaining useful life (RUL) of equipment in production lines using artificial neural networks. Their methodology employed a two-stage learning process where linear regression was used for interpolation of degradation data, followed by multilayer perceptron neural networks for final RUL prediction. The
study compared multiple algorithms including linear regression, random forest, and support vectordegradation trends, noting that "the results of other algorithms do not show a regular degradationtrend, and as such, it is difficult to fit with a polynomial curve." Their approach was validated using NASA turbofan engine datasets, demonstrating the effectiveness of linear regression for modelingregression for trend analysis in predictive maintenance applications, supporting the selection of
linear methods for capturing wheel damage progression patterns in railway systems.Taşcı et al. developed a machine learning-based approach for predicting the Remaining Useful
Life (RUL) of production lines in manufacturing using real-world IoT sensor data. Their study compared multiple regression algorithms including Random Forest, XGBoost, Multilayer Perceptron,
and Support Vector Regression for equipment failure prediction. Among the evaluated methods,
Random Forest achieved the best performance, followed closely by XGBoost for regression-based
RUL prediction. The implemented XGBoost regression model successfully prevented approximately 42% of actual production line failures in real-time deployment, demonstrating the practical effectiveness of XGBoost for continuous value prediction in predictive maintenance applications.This research validates the application of XGBoost for regression-based damage level prediction,
similar to the current study’s approach for wheel damage forecasting, though applied to differentin predictive maintenance for railway systems, with particular focus on wheel degradation and failure prediction. The research highlights both significant advances in methodology and persistent
challenges in data availability, model integration, and real-world implementation.## 4. Problem Formulationtrain tracks to monitor the forces acting on locomotive wheels in real-time. By applying machine learning algorithms to this sensor data, the aim is to predict the optimal time for wheel replacement,To narrow the scope and provide actionable insights, this study will specifically focus on three selected locomotives operating on the "Norra Stålpendeln" route between Borlänge and Boden.
in freight logistics, allowing for a detailed and controlled analysis. While this study focuses on locomotives, the goal is to develop a model that can later be extended to wagons and entire trains.- RQ1: How can Machine Learning algorithms be applied to sensor data, specifically force- RQ2: How can the most significant features be extracted to optimize wheel replacementMotivation: Railway maintenance is a critical aspect of ensuring safety, reliability, and cost efficiency in freight operations. Locomotive wheels experience significant wear and tear, and the ability to accurately predict their replacement needs can lead to substantial operational improvements. The choice of XGBoost, Isolation Forest and Linear Regression aligns with this
motivation, as these models are well-suited for handling large datasets with imbalances and complex feature interactions. While this study focuses on locomotives, extending the model to wagonsGoals: To achieve the purpose of this research and address the identified research questions,- Develop and implement a machine learning pipeline to process and analyze RFID sensor data- Identify the most significant data features for predicting wheel replacement.- Evaluate the performance of the prediction model using metrics such as R2, Root Mean- Assess the adaptability of the model for future use with wagons and entire trains.- Provide recommendations for integrating predictive maintenance solutions into existing railAssumptions and Limitations: The study assumes that the RFID sensor data is sufficiently accurate to reflect real-world conditions for the purposes of this analysis. However, the data may
still contain noise or inaccuracies that could impact the model’s performance. The exclusion of wagons limits the immediate generalizability of the findings, but the methodology is designed to be
adaptable for future studies involving entire trains. Furthermore, the analysis is geographically and operationally specific to the Norra Stålpendeln route, which may restrict its broader applicability.This creates a smooth transition: early predictions (days 0-150) rely primarily on XGBoost,
middle-term predictions blend both approaches, and long-term predictions (days 750+) rely primarily on linear trends, where 1095 represents the total forecast horizon in days (3 years = 3 × 365
days). The 0. cap was selected to ensure XGBoost always contributes at least 30% to predictions,
degradation patterns or operational anomalies that could affect wheel condition.Hybrid Integration Example: The time-dependent weighting creates a smooth transition fromThe mathematical progression: wlinear(t) = min(0.7, t/1095) demonstrates the gradual shiftAlternative Model Comparison: Random Forest was rejected due to bootstrap sampling being unsuitable for temporal forecasting where recent patterns should receive higher weight than
historical averages. Neural Networks were excluded due to insufficient training data per axle (834
measurements per axle) and black-box nature incompatible with safety-critical applications. Sup## 5. MethodStålpendeln route between Borlänge and Boden. The sensors measure vertical force impacts as train wheels pass over them, providing continuous monitoring of wheel condition. The dataset
encompasses 15,000 measurements from three locomotives (M4004, M4008, M4016), each equippedand right wheels, recorded with timestamps and associated vehicle identification. These force measurements directly relate to wheel condition, as damaged wheels create larger impact forces
when passing over the sensors. The axle weight measurements were also included to account forThe feature engineering process was designed to capture multiple aspects of wheel degradation.This metric directly quantifies localized damage severity. When wheels are healthy, forces are distributed evenly around the wheel circumference, resulting in peak values close to mean values
(small dynamic). When damage occurs at specific locations, those points experience significantly- Rolling statistics using adaptive window sizes: Calculated using a sliding window ap
proach where window size = min(10, total measurements available). For each measurement,- Days since start and measurement index: Days since start calculated as:Measurement index is simply the sequential position (1, 2, 3, ...) of each measurement within- Encoded vehicle and axle identifiers: Categorical variables converted to numerical valuesusing Label Encoding, where each unique vehicle/axle receives a sequential integer identifier- Rolling mean of dynamic values: Computed using the same sliding window approach asrolling statistics above, applied specifically to the dynamic damage values to reduce shortterm noise while preserving underlying degradation trends.The window size of 10 was selected to balance capturing recent trends while maintaining statistical stability. With the observed measurement frequency, this approximates one week of operationalIsolation Forest was selected for anomaly detection due to its effectiveness with high-dimensional data and its ability to identify outliers without assuming any underlying data distribution. The
contamination parameter was set to 0.05, identifying the most extreme 5% of measurements asThe 5% contamination rate reflects the operational reality that extreme wheel force conditions are infrequent but critical in railway systems. Given the 15,000-measurement dataset, this identifies 750 anomalies which, when duplicated in the enhancement strategy, results in approximately
9.5% of the final training dataset consisting of extreme operational conditions - providing sufficientRather than removing these anomalies, the implementation enhanced the training data by duplicating them. This decision was based on the precautionary principle: if these extreme values
represent pre-failure conditions, removing them would eliminate the model’s ability to learn theseXGBoost predictions. This dual-model strategy addresses the inherent limitations of each methodThis provides stable, physically interpretable trend projections essential for long-term planning.XGBoost excels at capturing complex non-linear patterns but requires known feature valuesheterogeneous features, its built-in regularization to prevent overfitting, and its ability to provide
feature importance metrics crucial for answering the research questions.A global training strategy was adopted after empirical testing of alternatives:- Individual axle models: Failed due to insufficient data (approximately 834 data points- Global models: Leveraged all available data while maintaining asset-specific informationGridSearchCV with 5-fold cross-validation systematically explored the hyperparameter space:- nestimators: – Below 300 showed underfitting; above 700 provided dimin- maxdepth: – Captures 4-8 levels of feature interactions without excessive complexity- learningrate: [0.05, 0.1, 0.15] – Balances convergence speed with training stability- subsample: [0.8, 0.9] – Introduces mild stochasticity while using most data- colsamplebytree: [0.8, 0.9] – Feature sampling to reduce overfittingThese ranges balance comprehensive search with computational feasibility, resulting in 540- 425 kN: Official Trafikverket threshold for mandatory wheel replacementThe 275 kN early warning threshold was selected to provide Green Cargo with internal alerts before Trafikverket’s regulatory warnings are triggered. This enables maintenance teams to analyze
damage progression patterns and trends leading up to potential threshold exceedance, supporting risk-informed maintenance decisions rather than purely reactive threshold responses. The 75 kN
step-down from the regulatory 350 kN warning level maintains consistency with Trafikverket’s framework while providing additional lead time for proactive maintenance planning.- Each fold maintains chronological order (no future data in training)The choice of 5 folds is a commonly accepted compromise that balances bias and variance in model evaluation. Using fewer folds (e.g., 3) can lead to higher bias and less reliable estimates,
while more folds (e.g., 10) increase computational cost and may reduce the size of validation sets,
especially with limited data. With temporal data, 5 folds provide enough data in each training set
to capture temporal patterns while preserving a strict forward-looking evaluation.- Coefficient of determination (R2) for scale-independent performance comparison- Root Mean Square Error (RMSE) for absolute prediction accuracy in kN unitsFeature importance analysis addresses Research Question 2 by quantifying the relative contribution of each input feature to model predictions. XGBoost calculates importance scores during tree
construction, where importance represents the average gain contributed by each feature when usedsets (e.g., LeftDynamic vs RightDynamic), feature importance is calculated through equivalentThis approach provides unified feature rankings while accounting for both wheel positions,Monte Carlo simulation with 100 iterations calculates prediction uncertainty. This number balances computational time (approximately 15 minutes for full fleet) with adequate sampling of the1. Adds stochastic noise scaled to 30% of historical volatility: Random noise is addedconditions and measurement errors. The noise level is calibrated to reflect realistic variability observed in the training data, though not explicitly calculated from historical volatility as
standard deviation of damage changes over time. Instead, the noise magnitude is through testing chosen to balance realism and signal clarity. The noise simulates unpredictable factors
such as varying load conditions, track irregularities, and measurement uncertainty that affect2. Propagates uncertainty through both model components: The added noise affectsboth the linear regression trend projection and the XGBoost feature inputs. For linear regression, noise is added directly to the trend-based damage progression. For XGBoost, the noisy
values become inputs for dynamic features, rolling statistics, and temporal variables, allowing the model to predict how uncertainty in current conditions affects future damage levels. This
ensures that uncertainty is consistently carried through the entire hybrid prediction process.3. Calculates percentile-based confidence intervals (10th and 90th): After 100 simu
lation iterations, the 10th and 90th percentiles of the prediction distribution are extracted to
create 80% confidence intervals. These percentiles were chosen to provide meaningful uncertainty bounds without being overly conservative (95% intervals) or overly narrow (50% intervals). The resulting intervals indicate that 80% of potential outcomes fall within the specified
range, providing maintenance planners with realistic uncertainty estimates for scheduling decisions.The 30% scaling prevents unrealistic uncertainty growth over the 3-year forecasting period- Both wheels on an axle replaced simultaneously (operational constraint): Thisconstraint is implemented by treating axle replacement as a single decision event. When either wheel reaches a damage threshold, the entire axle (both wheels) is scheduled for replacement.
The algorithm identifies the replacement timing but applies it to the complete axle unit,
reflecting real–world maintenance practices where replacing both wheels at the same time is- First wheel to exceed threshold triggers replacement: The implementation iter ates through each day of the 3-year forecast for both wheels, identifying the earliest day when either wheel’s predicted damage exceeds a threshold. The replacement schedule uses
‘min(leftexceeddays, rightexceeddays)‘ to determine axle replacement timing. For example, if the left wheel is predicted to exceed 275 kN on day 800 and the right wheel on day- Three threshold scenarios provide sensitivity analysis: The algorithm processes eachaxle through three threshold levels (275 kN early warning, 350 kN regulatory warning, 425
kN mandatory replacement) sequentially. For each threshold, it determines: (a) which wheel will fail first, (b) the exact timing in days, and (c) whether replacement is needed within
the 3-year forecast horizon. This generates three maintenance scenarios per axle, allowing## 6. Ethical and Societal Considerationswheels, presenting several ethical and societal considerations worthy of examination.While this study does not involve human subjects, it does utilize sensitive industrial data that- Confidential Data Management: Several aspects of the data used in this research are con
fidential, including specific sensor measurement values, actual maintenance costs and wheel lifespan information. This research respects these confidentiality requirements by avoiding the publication of raw data values, specific cost figures, or proprietary technical specifications of wheel components. All results are presented in a manner that protects Green Cargo’s- Data Integrity: The accuracy and reliability of sensor data analysis are essential, as inac
curate predictions could potentially affect maintenance planning and operations.- Transparency and Reproducibility: While protecting confidential information, method
ology has been documented to ensure scientific reproducibility of the research approach.The potential implementation of machine learning-based predictive maintenance carries several- Potential Resource Optimization: This research aims to develop models that could helppredict more optimal wheel replacement timing, potentially reducing instances of premature- Operational Planning: By forecasting maintenance needs more accurately, railway op
erators may be able to better plan maintenance activities, potentially reducing unplanned- Resource Conservation: If successful, more precise maintenance scheduling could con- Support for Rail Transport: Improving maintenance practices supports rail freight asa transportation mode, which generally has lower environmental impact per ton-kilometer- Proactive Maintenance: Early detection of wheel degradation patterns could potentiallyhelp identify issues before they lead to operational problems, contributing to overall railway- Algorithmic Transparency: The selected machine learning models (XGBoost and Isola
tion Forest) offer a balance between predictive capability and interpretability, allowing for- Human Decision-Making: The research proposes systems to support rather than replacehuman decision-making in maintenance planning, maintaining essential human oversight ofThis research aims to explore technological innovations for maintenance optimization while respecting confidentiality requirements and considering the broader economic, environmental and## 7. ImplementationThe implementation uses raw DPC sensor measurements into actionable 3–year maintenance forecasts through a four–stage pipeline designed to address the specific challenges of railway wheel
damage prediction. The challenges primarily includes limited per-axle data, heterogeneous fleetStage 1: Data Preparation and Feature Engineering The pipeline begins by calculating dynamic damage indicators immediately upon data loading, as these engineered features form the
foundation of all subsequent analysis. The implementation prioritizes this calculation because theavailability across the fleet. Newer axles with potentially limited operational history, receive proportionally smaller rolling windows, while established axles utilize the full 10-measurement context.
This design ensures all axles can be processed while maximizing the use of available historical information.Stage 2: Global Model Strategy Empirical testing revealed that individual axle models failed due to insufficient data (approximately 834 data points per axle), the implementation adopts a
global approach that pools all 15,000 measurements. This strategy addresses the fundamental
data insufficiency challenge while preserving asset-specific information through categorical encoding, enabling the model to learn both universal damage patterns and vehicle-specific characteristics.Stage 3: Anomaly-Enhanced Training The implementation employs a novel anomaly enhancement strategy rather than traditional anomaly removal. Isolation Forest identifies extreme
operational conditions (5% contamination threshold), but rather than removing these samples, the system doubles their representation in the training set. This decision is based of the safety-critical
nature of wheel maintenance, where rare extreme conditions may represent pre–failure states thatStage 4: Hybrid Forecasting Framework Long–term forecasting combines XGBoost pattern recognition with linear trend extrapolation through a time–dependent weighting scheme. This hybrid approach addresses the fundamental challenge that XGBoost requires feature projection into
the future, which becomes increasingly uncertain over extended time horizons.The data processing, modeling, and analysis were implemented using Python 3.10. The following
libraries and their respective versions were utilized to ensure reproducibility:Development was performed using the PyCharm IDE for code management and debugging.Global vs. Individual Modeling Strategy The choice of global modeling directly determines the exceptional performance metrics reported in Section 8.1. Individual axle approaches weretested but failed to achieve stable predictions due to insufficient training data. The global approach enables R2 scores exceeding 0. by leveraging the full 15,000-measurement dataset whileFeature Engineering Implementation Dynamic damage calculation serves as the primary feature because it is a direct indicator of wheel damage. The implementation computes this as:df [ ’ Left Wheel Damage Peak Value ’ ] − df[ ’Left Wheel Damage Mean Value’]df [ ’ Right Wheel Damage Peak Value ’ ] − df[ ’Right Wheel Damage Mean Value’]This engineering choice directly contributes to the 58.3% feature importance of dynamic indicators reported in Section 8.4, validating the implementation’s alignment with physical understanding.Anomaly Enhancement Strategy Traditional anomaly detection removes outliers, but railway maintenance requires learning from extreme conditions. The implementation increases anomalyXrightenhanced = np. vstack ([ Xright, Xright [ rightanomalies ] ] )yrightenhanced = np. concatenate ([ yright, yright [ rightanomalies ]])yleftenhanced = np. concatenate ([ yleft, yleft [ leftanomalies ]])This increases anomaly weight from 5% to approximately 9.5% of the training set, ensuring rare patterns receive enough learning attention without overwhelming normal operational patterns.Hybrid Forecasting Logic The time-dependent weighting implementation addresses XGBoost’sfinalprediction = weightlinear ∗ lineartrend + weightxgb ∗ xgbpredictionThis creates a smooth transition from XGBoost-dominated short–term predictions (high accuracy) to linear–dominated long-term predictions (high stability), directly enabling the reliableGridSearchCV Strategy Hyperparameter optimization explores the full parameter space using 5-fold cross-validation with R2 scoring. The implementation discovers significantly differentgreater model capacity, a finding that emerges directly from the data–driven optimization process.Cross-Validation Implementation The 5–fold cross–validation strategy ensures robust hyperparameter selection while preventing overfitting. The implementation forms the splits to maintain
representative vehicle-axle distributions across folds, contributing to the strong generalization performance (CV R2 scores of 0.9975 and 0.9873) reported in Section 8.1.Feature Projection Strategy Long–term forecasting requires projecting features into the future.- Temporal features: Increment linearly (dayssincestart += 1 per day)- Dynamic features: Project using historical trends with stochastic variationMonte Carlo Uncertainty Quantification The implementation uses 100–iteration Monte Carlo simulation to quantify prediction uncertainty. Each iteration adds stochastic noise scaled to 30%The 30% volatility scaling prevents unrealistic uncertainty explosion over 3 years while maintaining realistic operational variation. This implementation enables the confidence intervals (±0.# Prevent negative dynamics (ensuring peak is greater than mean)These constraints ensure predictions remain physically meaningful, contributing to the realistic maintenance forecasts that show only one axle requiring replacement within three years.threshold levels (275, 350, 425 kN) to provide sensitivity analysis. For each threshold, the systemfirstwheel = ’Left’ if leftexceeddays <= rightexceeddays else ’Right’either one exceeds a threshold, directly generating the maintenance schedules reported in the Section 8.3.2.Fleet-wide Analysis Pipeline The implementation processes all 18 vehicle–axle combinations
systematically, generating individual forecasts and aggregating fleet-wide maintenance requirements. This comprehensive approach enables the results in Section 8.3.2, finding that only one axle across the entire fleet requires replacement within three years at the 275 kN threshold.through train–test splits (80-20) with vehicle-stratification to ensure representative sampling.
Cross-validation scores validate hyperparameter selection, while residual analysis confirms model assumptions. This validation framework directly supports the exceptional performance metricsComprehensive Output Generation The system produces multiple output formats:- Individual forecast plots for each vehicle-axle combination with uncertainty bands- CSV maintenance schedules with replacement timing for each threshold scenarioComputational Performance The implementation achieves practical deployment performance:- Model training: approximately 30 minutes including GridSearchCV optimization- Total pipeline: <35 minutes from raw data to actionable maintenance schedulesThis performance enables regular fleet assessment and maintenance planning updates in operational environments.From Implementation to Performance Metrics The exceptional model performance (R2strategy providing sufficient training data, feature engineering capturing physical damage phenomena, and anomaly enhancement ensuring learning from extreme conditions. Alternative approaches
tested during implementation (individual axle models, standard anomaly removal) failed to achieveFrom Feature Engineering to Feature Importance The dominance of dynamic damage indicators (58.3% importance) in Section 8. directly validates the implementation’s focus on dynamic calculations. The rolling statistics contributing 10.7% importance demonstrate how the adaptiveFrom Hybrid Approach to Maintenance Predictions The minimal maintenance requirements identified in Section 8.3. (one axle replacement in three years) result from the hybrid
forecasting implementation, balancing pattern recognition with trend stability. Pure XGBoost
approaches tested during development produced less stable long–term predictions, while pure linear extrapolation missed complex damage patterns, validating the hybrid implementation strategy.This implementation framework transforms raw sensor measurements into reliable long–term maintenance forecasts, directly provides insights for a potential transition from reactive threshold-based
maintenance to proactive predictive planning demonstrated in Section 8..## 8. ResultsThe XGBoost models achieved near-perfect performance across all evaluation metrics .
The left wheel model demonstrated a perfect test R2 score of 1.0000 with an RMSE of 0. kN,
while the right wheel model achieved a test R2 of 0.9993 with an RMSE of 0. kN. Cross-validation scores of 0.9975 (left) and 0.9873 (right) confirm strong model stability and generalization acrossThe analysis reveals notable performance differences between wheel positions, with left wheel models achieving superior accuracy (R2 = 1.0000, RMSE = 0. kN) compared to right wheel models
(R2 = 0.9993, RMSE = 0. kN). The right wheel model shows 4. times higher prediction error,
suggesting systematic factors affecting wheel position measurements differently.Several potential contributing factors may explain these differences. As described in Section 2.3.1,
wheels depending on wheel oscillation patterns and contact positioning during passage. Different operational load distributions, noted as factors not included in this thesis, could create asymmetric wear patterns between wheel positions. Additionally, track–specific wear characteristics may result in different deterioration rates on each side of the rails, while certain wheel surface areas may be
more prone to damage development – aspects not investigated in this study. The higher variability in right wheel predictions (RMSE 0. kN vs 0. kN) suggests that right wheels may exhibitWhile these results appear outstanding, several factors warrant careful consideration. The extremely high R2 values (>0.99) raise potential concerns about overfitting, despite showing no
generalization gap between training and test performance. However, several factors support the- Physical consistency: The RMSE values (0.08-0. kN) are small relative to the damagethreshold ranges (275-425 kN), representing approximately 0.08-0.09% prediction error- Cross-validation stability: The modest gap between test R2 and CV R2 (0.0025 for left,0.0120 for right) indicates genuine predictive capability rather than data leakage- Feature interpretability: The model’s reliance on physically meaningful features (dynamicThe parity plots demonstrate strong correlation between predicted and actual values
across the full range of damage levels, with prediction intervals providing realistic uncertaintyintervals for both left and right wheel models. The strong correlation along the diagonal indicatesprovides a key methodological strength. Individual axle-specific models failed due to insufficient
data (approximately 834 points per axle), while the global approach leveraged all 15,000 measurements for training while preserving asset-specific patterns through categorical encoding. This
strategy provides substantial training data volume (15,000 samples) while enabling predictions for individual axles, effectively solving the data insufficiency problem that would plague axle–specificThe dynamic damage indicator (Peak − Mean) proved to be the most critical engineered feature,
representing 58.3% of model importance. This metric successfully captures the fundamental physics of wheel damage: healthy wheels distribute forces evenly (small dynamic values), while damagedIsolation Forest identified 750 anomalies per wheel (5% of data) representing extreme operational
conditions. Rather than removing these outliers, the enhancement strategy increased their representation to 9.5%, ensuring the model learns from rare but potentially critical pre–failure patterns.
The isolation forest analysis shows these anomalies cluster around extreme peak valuesversus detected anomalies across different feature dimensions. Anomalies (red points) clusterThe 3–year forecasting analysis across all 18 vehicle-axle combinations reveals different degradation
patterns . The implementation generated forecasts for 1,095 days, revealing significantprogression patterns. Each subplot represents one axle, with separate lines for left (blue) and right
(red) wheels, illustrating the diversity of degradation patterns across the fleet.Analysis of historical trends across all 18 axles shows mixed patterns across the fleet:- Improving conditions: 9 left wheels and 7 right wheels show decreasing damage trends- Deteriorating conditions: 9 left wheels and 11 right wheels show increasing damage trendskN/day left, -0.0185 kN/day right) from current levels of 142 kN (left) and 116 kN (right).kN/day left, 0.1338 kN/day right) from current levels of 128 kN (left) and 124 kN (right), representing the degrading condition that leads to predicted threshold exceedance.The selected examples illustrate this diversity: M4004the improving condition scenario with negative trends leading to no predicted maintenance needs,Axle 3 demonstrates how positive historical trends translate intoThe forecasting analysis identified minimal immediate maintenance needs:This outcome suggests excellent current fleet condition. The single predicted replacement corresponds to M4008
Axle 3, which exhibits the highest positive damage trend (0.1456 kN/dayFigure 10 & Figure 11 illustrates representative prediction scenarios from the 18 individual axlelevels of 116-142 kN with slight negative trends result in no predicted threshold crossings within(0.1456 kN/day left, 0.1338 kN/day right) from current levels of 124-128 kN lead to predicted 275
kN threshold exceedance in Year 3, representing the single replacement case identified.No threshold exceedance (majority case): Most axles, such as M4004
show slight negative trends (-0.0132 to -0.0185 kN/day), resulting in no predicted threshold crossings within the 3–year forecasting horizon.Threshold exceedance case: M4008
kN/day left, 0.1338 kN/day right) from current levels (128-124 kN), leading to predicted 275 kNStable condition cases: Several axles like M4016
kN/day) from moderate baselines (112-121 kN), indicating stable long–term condition.The Monte Carlo simulation reveals variation in prediction uncertainty across axles, directly reflecting their historical behavioral patterns. Assets with consistent operational history (M4004
1) produce narrow 80% confidence intervals suitable for reliable maintenance planning, while axlesshowing inconsistent damage (M4008
This asset–specific uncertainty quantification enables different maintenance strategies, where highconfidence predictions support standard scheduling while high–uncertainty predictions indicate theThe feature importance analysis reveals a clear hierarchy of predictive factors (methodology described in Section 5.8.3), with dynamic behavior dominating the prediction model .to the XGBoost model predictions. Dynamic damage indicators dominate the model with 58.3%
importance, followed by baseline damage levels and rolling statistics.1. Dynamic Behavior (58.3% importance): The difference between peak and mean damagevalues turned out to be the dominant predictor across both wheel models, confirming that2. Baseline Damage Level (25.2%): Historical damage levels provide essential context for3. Rolling Statistics (10.7%): Temporal smoothing of dynamic values captures medium-term4. Load Factors (3.8%): Axle weight influences damage progression but represents a second5. Asset-Specific Factors (0.9%): Vehicle and axle encoding show minimal but measurableBoth left and right wheel models demonstrate consistent feature importance patterns, with dynamic damage indicators dominating predictions (59.3% for left wheels, 57.3% for right wheels).
This consistency validates the global modeling approach and confirms that wheel damage mechanisms are similar across wheel positions.
The strong agreement between models (difference of only 2.0% for dynamic behavior importance)Primary monitoring focus: The dominance of dynamic features (58.3%) indicates that realtime spike detection should be the cornerstone of any monitoring system. Maintenance schedules
should prioritize wheels showing increasing peak-to-mean differences rather than absolute damageSecondary indicators: Mean damage values (25.2%) provide essential baseline context, suggesting that maintenance decisions should consider both current spike severity and historical condition trends.Load management: The modest influence of axle weight (3.8%) suggests that while loading affects damage progression, it is not the primary driver of replacement timing decisions.The residuals analysis reveals well-behaved prediction errors with minimal systematicnormal distribution with minimal systematic bias indicates good model performance, though rightThe residual analysis validates the regression metrics described in Section 5.8.2:or potential systematic differences in measurement conditions between wheel positions.Linear regression analysis provides validation context for the XGBoost predictions and demonstrates how historical trends inform future forecasting. The representative examples (Figures 8
and 9) show how different historical patterns lead to different maintenance outcomes:M4004
Axle 1 exemplifies the majority scenario where decreasing historical trends (-0.0132
and -0.0185 kN/day) from moderate baseline levels (142 and 116 kN) result in continued so called
"improvement", leading to no maintenance requirements within the 3-year forecast horizon .M4008
Axle 3 represents the minority deteriorating case where positive historical trends (0.1456
and 0.1338 kN/day) from similar baseline levels (128 and 124 kN) drive the system toward the 275
kN threshold, resulting in the single predicted replacement out of 18 axles for a 3–year forecastinglinear trends into actionable maintenance predictions, with the linear component providing longterm stability while XGBoost captures complex patterns in the shorter term.Dynamic damage indicators (58.3% importance) directly predict replacement needs because higher peak–minus–mean values indicate localized wheel defects that create force spikes during detector
passage. As damage severity increases, these spikes become more pronounced, providing a directBaseline damage levels (25.2% importance) influence predictions by providing context for interpreting dynamic spikes - the same dynamic value has different implications depending on the
underlying wheel condition. Rolling statistics (10.7% importance) capture degradation trends that
distinguish temporary anomalies from progressive deterioration requiring intervention.While XGBoost feature importance reveals which features matter most, it cannot explain individual prediction decisions. Advanced explainable AI techniques such as SHAP (SHapley Additive exPlanations) could provide instance–level explanations, enabling maintenance teams to understand specific factor contributions for each wheel. Studies like Li demonstrated successful
application of SHAP for interpreting XGBoost models, showing how local interpretation methods
can extract meaningful explanations from complex ensemble models. Similar application could enhance Green Cargo’s maintenance decision–making by providing detailed rationale for individual## 9. DiscussionHow can Machine Learning algorithms be applied to sensor data, specifically forcepredict wheel replacement needs, but with important methodological considerations. The global
XGBoost approach proved essential for handling the heterogeneous fleet data, achieving exceptional performance metrics (R2 > 0.99) by leveraging all 15,000 measurements while preservingThe finding of the dynamic damage indicator (Peak − Mean) as the dominant feature (58.3%
importance) directly validates the theoretical framework established in Section 2.. As described in
Section 2.3.1, the conical wheel geometry creates concentrated contact points that produce "specific force patterns" where "damaged wheels create irregular patterns as different surface conditions
pass over the detectors." The model’s reliance on this feature confirms that ML can effectively capture these physics–based damage signatures.The usage of Isolation Forest for anomaly enhancement rather than removal addresses a critical challenge in railway maintenance: rare but potentially critical pre–failure conditions. By
increasing the representation of the most extreme 5% of measurements, the approach ensures the model learns from unusual patterns that might represent the "irregular patterns" characteristic ofHowever, the application faces significant limitations related to data availability and validation9.1. RQ2: How can the most significant features be extracted to optimize wheelFeature Engineering Process: Significant features were extracted through physics–based engineering, creating dynamic damage indicators (peak–minus–mean) that capture the fundamental
wheel–rail contact mechanics. This engineering approach transforms raw sensor measurements intoGlobal Modeling for Feature Assessment: The global modeling strategy enables robust
feature importance evaluation by leveraging data from all assets while preserving individual characteristics through categorical encoding. This approach provides sufficient data volume for reliableXGBoost-Based Feature Ranking: The model’s built–in feature importance calculation during tree construction provides quantitative, data–driven identification of predictive factors. This
method ranks features based on their actual contribution to prediction accuracy rather than assumptions.Validation Through Performance: Feature significance was validated through exceptional
model performance (R2 > 0.99), confirming that the extraction methodology successfully identified meaningful predictive patterns.The methodology reveals that dynamic damage indicators dominate predictions (58.3% importance), followed by baseline conditions (25.2% importance) and temporal patterns (10.7% importance), providing clear guidance for maintenance system optimization.The results reveal notable differences between the ML–based predictive approach and Green
Cargo’s current threshold–based system described in Section 2.. Currently, Green Cargo operates with Trafikverket’s regulatory limits (425 kN mandatory replacement, 350 kN warning) in a
reactive framework that "only responds to exceedances of predefined limits, rather than forecasting275 kN early warning threshold, while no axles approach the current 350-425 kN operational- The fleet condition is significantly better than anticipated based on the "significant wear and- The predictive approach enables maintenance scheduling well before current reactive triggersThe ML approach provides several advantages over the current threshold–based system:- Proactive forecasting: 3–year maintenance schedules versus reactive threshold responses- Uncertainty quantification: Confidence intervals for maintenance planning versus binary- Pattern recognition: Complex damage signatures versus simple threshold exceedance- Fleet-wide optimization: Coordinated maintenance scheduling versus individual assetThe results strongly validate the theoretical understanding of wheel-rail dynamics established in the background 2.. The dominance of dynamic features (58.3%) aligns perfectly with the physics
of limited wheel–rail contact, where "localized damage or wear" creates detectable force spikes even when damage occurs on "portions of the wheel that don’t make regular contact with the rail"The hybrid forecasting approach addresses the background observation that "multiple measurements needed" by combining short–term XGBoost pattern recognition with long–term linear trend
extrapolation. This methodology effectively handles the geometric constraint where "wheel damage might not always align with the sensor during a single pass."The identification of M4008
Axle 3 requiring replacement demonstrates that the approach can detect "irregular patterns as different surface conditions pass over the detectors," validating the
theoretical framework while providing actionable maintenance insights.validation. This limitation is particularly critical given the background emphasis on the Transmontana locomotives’ "metal-against-metal" braking systems that "cause significant wear and
tear on the wheels." The analysis was designed around the expectation that these systems would
"generate substantial wear and tear data, offering a rich dataset for modeling and analysis" with9.4. Temporal and External Factors Influencing Degradation PredictionsWhile the dataset includes approximately 834 data points per axle, providing a robust basis for model training, it may not fully capture the long–term degradation cycles or seasonal variations
expected under the described harsh operational conditions. Although the models leverage all available data, the temporal span of the observations may restrict their ability to predict patternsAdditionally, the relatively low predicted replacement rate, only 1 axle across 18 axles over three
years, may result from factors beyond the scope of this thesis, including:- Operational Factors: Current practices, such as effective load balancing and preemptivemaintenance, may mitigate wear more effectively than initially anticipated.- Measurement Limitations: The geometric constraints of wheel–rail contact may preventdetection of certain damage types, potentially underestimating degradation.- External Influences: Unaccounted factors such as weather conditions, track quality vari
ations, and seasonal temperature effects could significantly impact damage progression.contextual variables in future analyses to ensure the predictions align more closely with long–termWhile the extremely high R2 values (>0.99) appear exceptional, they warrant careful interpretation. The strong cross–validation performance (0.9975 and 0.9873) and substantial training dataset (15,000 measurements) support genuine predictive capability rather than overfitting. However,The exceptional performance might indicate that wheel degradation follows more predictable patterns than anticipated, or conversely, that the current dataset lacks the variability expected fromthreshold–based maintenance to proactive forecasting. The ability to generate 3–year maintenance- Resource optimization: Coordinated scheduling of maintenance activities across the fleet- Inventory management: Predictable wheel replacement needs for supply chain planning- Operational continuity: Advance scheduling to minimize service disruptions- Cost reduction: Elimination of emergency maintenance through proactive interventionThe feature importance findings provide guidance for optimizing Green Cargo’s monitoring investments. The dominance of dynamic damage indicators suggests that sensor systems should- High-resolution force spike detection over absolute load monitoring- Pattern recognition capabilities for identifying irregular contact signatures- Historical trend analysis rather than instantaneous threshold comparison- Integration of multiple measurement points to address geometric detection limitationsThe minimal maintenance requirements predicted within Trafikverket’s threshold framework suggest potential opportunities for threshold optimization. Green Cargo could consider:- Implementation of lower early-warning thresholds (e.g., 275 kN) for enhanced lead time- Development of asset–specific thresholds based on operational history and model predictions- Integration of uncertainty bounds into threshold-based decision makingwheel maintenance in railway operations. Both research questions were answered:RQ1 was addressed through the successful implementation of a global XGBoost modeling strategy that processes DPC sensor data to predict wheel replacement needs, validated through performRQ2 was answered through systematic feature extraction methodology combining physics-based
engineering, global modeling assessment, and data-driven ranking techniques, successfully identifying the most predictive factors for wheel replacement optimization.The hybrid forecasting methodology enables Green Cargo to potentially transition from reactive threshold–based maintenance to proactive 3–year maintenance planning, directly addressing
the stated purpose of improving decision–making and reducing operational risks.However, the absence of actual failure validation data means that while the technical objectives were achieved, operational validation remains incomplete. The study demonstrates the feasibility
and potential of ML–based predictive maintenance but requires additional validation against confirmed failure events.This study contributes several methodological insights to railway predictive maintenance:preserving asset–specific learning through categorical encoding. This strategy could be applied toshort–term accuracy and long–term stability. The time–dependent weighting scheme offers a practical solution for long–horizon forecasting in equipment condition monitoring.The decision to enhance rather than remove anomalies addresses a critical challenge in safetycritical systems where rare events may represent the most important learning opportunities. This
approach could inform anomaly handling strategies in other predictive maintenance applications.prediction accuracy against real operational outcomes rather than threshold exceedance. ThisLonger observation periods (3-5 years) would enable validation of long-term forecasting accuracy.Integration of additional sensor types (vibration, temperature, acoustic) could address the geometric limitations of force–based detection and provide more comprehensive condition assessment.Future models should incorporate operational variables (weather, track conditions, loading patterns, operational changes) to improve prediction accuracy and provide more comprehensive understanding of degradation factors.The methodological contributions of this study extend well beyond Green Cargo’s specific operational context, offering several generalizable approaches for predictive maintenance in asset–are insufficient for reliable predictions. This approach could, for example, be applied to:The hybrid forecasting framework combining ML pattern recognition with linear trend extrapolation provides a robust approach for long–horizon predictions in any sensor–based monitoring
system. The methodology is particularly applicable to industries where:- Equipment operates under similar conditions but with asset–specific variationsThe anomaly enhancement strategy offers valuable insights for safety–critical applications where rare events may represent the most important learning opportunities. This approach has relevanceMany industries currently rely on threshold–based maintenance similar to Green Cargo’s approach.The methodology demonstrates strong potential for scaling across Green Cargo’s entire fleet and broader railway operations, as the standardized DPC detector infrastructure provides consistentacross different routes, as the DPC detectors collect identical data types (peak load, mean load,
timestamps) regardless of location. The global modeling strategy successfully integrates data from multiple assets while preserving asset–specific characteristics through categorical encoding,
enabling seamless expansion to the entire fleet without requiring route–specific model development.For high–speed passenger services, the core methodology remains applicable since these systems utilize the same DPC detector infrastructure and data collection protocols. While high–speed trains
with advanced braking systems generate different force magnitude patterns, the fundamental data structure and feature engineering approaches remain unchanged. The higher operational frequency
could potentially enhance model training through increased data density.The methodology can be scaled across European railway networks where standardized DPC detector infrastructure exists. Since the data collection methodology is consistent across different
railway systems, the same global modeling approach can be applied to international operations,
enabling coordinated predictive maintenance strategies across borders while leveraging the standardized sensor infrastructure.The key advantage is that the data structure remains constant across all applications - only the actual force values differ based on operational conditions, making the methodology highly scalableThe study’s emphasis on uncertainty quantification and confidence intervals addresses a critical need in maintenance decision–making across industries where safety and reliability are paramount,For Green Cargo to implement this predictive maintenance approach effectively, several practical considerations must be addressed:Implementation requires robust data collection, processing and analysis infrastructure capable of handling real–time sensor data across the fleet while maintaining the computational efficiencyThe predictive approach must integrate with Green Cargo’s current maintenance managementAny implementation must maintain compliance with Trafikverket’s mandatory threshold limits
while leveraging predictive capabilities for enhanced operational efficiency within regulatory constraints.The extremely high R2 values, while supported by cross–validation and the substantial 15,000measurement training dataset, may indicate that the current dataset exhibits more regularity than
typical operational conditions. However, the global modeling approach provides sufficient data volume to support the model complexity and the strong cross–validation performance (CV R2 of
0.9975 and 0.9873) suggests genuine predictive capability rather than overfitting.Several operational factors not captured in this study could significantly affect model robustness.
Seasonal weather conditions such as winter snow, ice, and temperature variations alter wheel–rail
contact characteristics and may create different damage patterns than those observed in the current dataset. Similarly, varying braking patterns across different operational scenarios - including
emergency braking frequency and different braking intensities - could produce wheel wear characteristics not represented in the current analysis.Route–specific characteristics of the Borlänge-Boden line present another limitation. Different routes have distinct gradient profiles, curve distributions, track conditions, and operational speeds
that create unique damage progression patterns. The current model’s training on a single routeThe limitation to three locomotives operating a single route significantly constrains the model’s generalization capabilities. While this approach provides deep insights into specific operational conditions, it restricts exposure to the broader spectrum of locomotive behaviors, operationalAdditional data sources could substantially improve generalization. Incorporating data from multiple routes with diverse track characteristics would expose the model to different operational
stresses. Extended temporal coverage spanning multiple seasons would capture weather–related variations in damage patterns. Including locomotives with different operational roles, braking patterns, and maintenance histories would enhance the model’s ability to handle diverse fleet characteristics. Integration of weather data and route–specific information could provide additional
context for understanding damage progression variability across different operational environments.The results demonstrate significant practical value for Green Cargo’s maintenance operations:- Computational efficiency: 35-minute total processing time enables regular fleet assess- Actionable outputs: Clear maintenance schedules with confidence intervals- Uncertainty quantification: Monte Carlo simulation provides realistic prediction bounds- Scalability: Global modeling approach can accommodate fleet expansion## 10. Conclusionsmaintenance in railway operations, making several important contributions to the field.My approach introduced three main innovations. First, I developed a global modeling strategy that asset–specific patterns through categorical encoding. Secondly, I created a hybrid forecasting
reliable long–term predictions. Thirdly, instead of removing extreme operational conditions from the data like most approaches do, i used an anomaly enhancement method that learns from these
extreme conditions, which is crucial for safety–critical railway systems.feature, accounting for 58.3% of the model’s importance. This finding provides clear guidance for optimizing sensor systems in future implementations. The model also successfully measures
prediction uncertainty for individual assets, which helps maintenance teams make better riskinformed decisions. Most importantly, this approach enables a shift from reactive threshold–based
maintenance to proactive 3–year forecasting with quantified uncertainty levels.The model achieved excellent predictive accuracy with R2 values above 0. while maintaining computational efficiency with just 35–minute processing times. When applied to real fleet data, it
generated actionable maintenance schedules that identified minimal immediate needs, 1 out of 18
Looking ahead, several areas need more work, particularly incorporating actual failure data and extending observation periods to validate the long–term forecasting capabilities. The approach could also benefit from integrating additional sensor types and operational variables. The hybrid forecasting framework shows promise for other maintenance challenges across different industries.