{"text": "Abstract** **—Wheel defects on railway wagons have been identified as an important source of damage to the railway infrastructure and rolling stock. They also cause noise and vibration emissions that are costly to mitigate. We propose two machine learning methods to automatically detect these wheel defects, based on the wheel vertical force measured by a permanently installed sensor system on the railway network. Our methods automatically learn different types of wheel defects and predict during normal operation if a wheel has a defect or not. The first method is based on novel features for classifying time series data and it is used for classification with a Support Vector Machine.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 0, "year": "2008"}}
{"text": "he first method is based on novel features for classifying time series data and it is used for classification with a Support Vector Machine. To evaluate the performance of our method we construct multiple data sets for the following defect types: flat spot, shelling and nonroundness. We outperform classical defect detection methods for flat spots and demonstrate prediction for the other two defect types for the first time.****Motivated by the recent success of artificial neural networks for image classification we train custom artificial neural networks with convolutional layers on two-dimensional representations of the measurement time series.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 1, "year": "2008"}}
{"text": "tion we train custom artificial neural networks with convolutional layers on two-dimensional representations of the measurement time series. The neural network approach improves the performance on wheels with flat spots and nonroundness by explicitly modelling the multi sensor structure of the measurement system through multiple instance learning and shift invariant networks.****Index Terms** **—Machine learning, Statistical learning, Support vector machines, Pattern analysis, Railway safety, Railway accidents, Wavelet transforms, Supervised learning, Artificial neural networks**## I. INTRODUCTION**E** ARLY detection of serious wheel defects on freight trainsare an essential part in preventi", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 2, "year": "2008"}}
{"text": "tificial neural networks**## I. INTRODUCTION**E** ARLY detection of serious wheel defects on freight trainsare an essential part in preventing damage to the railway infrastructure and in providing the train operators with timely information on necessary repairs, that can prevent further deterioration of the wheels.Wheel defects of railway vehicles directly cause an increase in attrition of and damage to the railway infrastructure, e.g., the track systems or the civil engineering works, thereby adding additional costs to maintenance and repair and leading to a reduced lifetime and availability of rolling stock.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 3, "year": "2008"}}
{"text": "eering works, thereby adding additional costs to maintenance and repair and leading to a reduced lifetime and availability of rolling stock. The life span of the railway infrastructure is significantly shortened by the negative effects of wheel defects. The life span of railway bridges for instance is calculated with an assumed maximal dynamical load of 21 tons. Due to wheel defects the actually occurring dynamical load can be up to 50 tons, or 270% higher than the theoretically assumed maximum, thus shortening thelife span. Wheel defects also accelerate crack-growth on the rail tracks and lead to premature failure of the rail system.Another important effect caused by wheel defects are groun", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 4, "year": "2008"}}
{"text": " crack-growth on the rail tracks and lead to premature failure of the rail system.Another important effect caused by wheel defects are ground vibration and noise emissions. In the European Union (EU) Project “Railway Induced Vibration Abatement Solutions” (RIVAS) 27 partners from nine countries investigated the source and mitigation measures for noise and vibration emissions. They found that reducing wheel defects by wheel maintenance significantly reduces vibration and noise emissions directly . Therefore, it is recommended to use timely and targeted maintenance of train wheels as an economic means to reduce emissions .", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 5, "year": "2008"}}
{"text": "ns directly . Therefore, it is recommended to use timely and targeted maintenance of train wheels as an economic means to reduce emissions . This measure is all the more important as the density and usage of modern railway networks is steadily increasing and failures quickly disrupt operation of the whole network or parts of it. Since 2008, all states in the EU are advised to employ noise emission ceilings. Switzerland started a noise abatement program based on emission ceilings that requires the infrastructure manager to curb emissions above the ceiling. This abatement programme leads to total costs of 1.  billion CHF .In this paper we propose a method of detecting defective wheels.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 6, "year": "2008"}}
{"text": " ceiling. This abatement programme leads to total costs of 1.  billion CHF .In this paper we propose a method of detecting defective wheels. This classification method promises to increase the reliability of the railway infrastructure, to reduce the cost of freight train operation and to save additional investments on noise protection measures. To reach this goal without the costly construction of further measurement sites or newly built sensors, we propose the use of statistical methods that allow us to automatically inspect the existing data and extract the information about defective wheels that is already present.Our proposed methods do neither require a model of the measurement system,", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 7, "year": "2008"}}
{"text": "t the information about defective wheels that is already present.Our proposed methods do neither require a model of the measurement system, nor of train dynamics or wheel defects. The methods enable us to predict defects on wheels where there is no prior understanding of how these defects manifest themselves in the measurements. The methods detect and classify different types of defects based on measurements during normal operation where the trains pass the measurement sites in full operational speed. The features that we have developed for the use in supervised learning are general and can in principle be used for any time series data and are not restricted to specific defect types.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 8, "year": "2008"}}
{"text": "se in supervised learning are general and can in principle be used for any time series data and are not restricted to specific defect types. In a second step we automatically learn features directly from the raw measurement signal.## A. ContributionOur main contribution are two methods for automatic railway wheel defect detection and classification through vertical force measurements of trains running in full operational speed. For the first method we design novel wavelet features for time series data from multiple sensors and we learn a classifierusing a support vector machine. For the second method we design and train convolutional neural networks for different wheel defect types by deep l", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 9, "year": "2008"}}
{"text": "a support vector machine. For the second method we design and train convolutional neural networks for different wheel defect types by deep learning.We evaluate our novel and other classical methods for wheel defect detection on two labeled data sets with different types of wheel defects, that we have constructed from calibration runs and from maintenance reports.## B. Related WorkWhile there has been research on machine learning methods for railway track inspection [4–6] or condition based maintenance , to our knowledge machine learning methods for railway wheel defect detection have not been developed so far.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 10, "year": "2008"}}
{"text": "r condition based maintenance , to our knowledge machine learning methods for railway wheel defect detection have not been developed so far. There has been some research on sensor systems for wheel defect detection on freight trains. In Nenov, Dimitrov, Vasilev, et al. , the authors analyse the signal from acceleration sensors and demonstrate that they can visually see a difference between the measurements of wheels with flat spots and good wheels but they do not propose a method for detection. Another related work  advocates the use of Fibre Bragg Gating sensors for defect detection of rails to monitor track conditions.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 11, "year": "2008"}}
{"text": " detection. Another related work  advocates the use of Fibre Bragg Gating sensors for defect detection of rails to monitor track conditions. The authors investigate the wavelet decomposition of pressure signals but they do not propose a method or threshold for automatic defect detection. Jianhai, Zhengding, and Boshi  use continuous wavelet analysis of acceleration sensor data to visually inspect the measurements and conclude that there is a difference in the coefficients for wheel with flat spots and defect-free wheels.Different kinds of track scales are in use in the field. They can in principle be used to detect flat spots.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 12, "year": "2008"}}
{"text": "at spots and defect-free wheels.Different kinds of track scales are in use in the field. They can in principle be used to detect flat spots. But to our knowledge they do not use machine learning to train a defect classifier. A general advantage of our proposed system is that the measurement system is relatively inexpensive, but we can show that it can still be used to detect wheel defects, thanks to our proposed machine learning methods.## II. MEASUREMENT SYSTEM AND DEFECT TYPES## A. Wheel Load CheckpointThe infrastructure division of the Swiss railway operator SBB operates and maintains the one of the most heavily used railway network of the world. In 2010, 95 .", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 13, "year": "2008"}}
{"text": "vision of the Swiss railway operator SBB operates and maintains the one of the most heavily used railway network of the world. In 2010, 95 . 4 km of trains travelled one kilometer of track on average; this value documents the highest utilisation of network capacity in the world . Automatically monitoring trains and network are thus important to minimise the risk of incidents that quickly affect the scheduling of trains on the network. SBB infrastructure operates an integrated wayside train monitoring system that controls safety relevant aspects of the railway traffic and infrastructure.As part of this system, the wheel load checkpoints (WLC) measure vertical force through strain gauges insta", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 14, "year": "2008"}}
{"text": "ilway traffic and infrastructure.As part of this system, the wheel load checkpoints (WLC) measure vertical force through strain gauges installed on the rails. These devices are used for observing maximal axle load, maximal train load, load displacement and grave wheel defects. Our study investigates the use of machine learning methods to defect and classify wheel defects based on the data obtained through these wheel load checkpoints.Sensors<br>Wheel<br>Sleepers<br>**----- End of picture text -----**<br>Force<br>Path<br>Rail<br>Centerline<br>Sleeper<br>15 cm x 26 cm 16 cm 28 cm 16 cm<br>60 cm<br>**----- End of picture text -----**<br>Each WLC consists of four 1m long measurement bars with fo", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 15, "year": "2008"}}
{"text": "5 cm x 26 cm 16 cm 28 cm 16 cm<br>60 cm<br>**----- End of picture text -----**<br>Each WLC consists of four 1m long measurement bars with four strain gauges (referred to as sensors in the following) per measurement bar. Since on each side two measurement bars with 4 sensors are installed, each wheel that runs over the WLC is measured eight times at different parts of the wheel. Fig.  shows schematically the measurement of one wheel by one measurement bar. In this example a defect is directly observed by the measurement of the first sensor.See Fig.  for a diagram of one sensor. The strain gauges are installed perpendicular on the centerline of the railroad track and they are combined into one", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 16, "year": "2008"}}
{"text": " diagram of one sensor. The strain gauges are installed perpendicular on the centerline of the railroad track and they are combined into one vertical wheel force measurement. One sensor covers approximately 30cm of the wheel circumference.The wheel load checkpoints are installed on multiple strategic sites on the railway network: ten on the border to Switzerland at the entrance to the railway network maintained by SBB and a dozen within the network.## B. Railway Wheel DefectsA relatively well understood wheel defect type is the flat spot or wheel flat. This defect occurs when the wheel stops rotating (for instance during an emergency brake) and is dragged along the track. Fig.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 17, "year": "2008"}}
{"text": "r wheel flat. This defect occurs when the wheel stops rotating (for instance during an emergency brake) and is dragged along the track. Fig.  shows an image of a flat spot on a railway wheel of SBB and the corresponding idealized measurement obtained by the WLC if the flat spot directly hits a sensor of the measurement system. Grave wheel flats can be detected by looking at simple statistics (c.f. Section VI-B) of the measurement if the defect hits the sensor perfectly. To be able to detect flat spots that are less grave or that do not hit a sensor directly, more advanced machine learning methods are required.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 18, "year": "2008"}}
{"text": " be able to detect flat spots that are less grave or that do not hit a sensor directly, more advanced machine learning methods are required. We demonstrate such cases on our first data set in Section VII-B.Apart from flat spot, other common wheel defects on railway vehicles are non-roundness and shelling . Wheels with non-roundness have a high influence on the vibration and noise emitted by a passing train and, therefore, they are an important type of defect to detect . Non-roundness, in contrast to shelling and flat spot, is a non-discrete type of defect. This characterization means that the defect affects a large part of the wheel and changes its shape in a non-local way.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 19, "year": "2008"}}
{"text": "rete type of defect. This characterization means that the defect affects a large part of the wheel and changes its shape in a non-local way. We create an additional data set that contains the defect types flat spot, non-roundness and shelling  and then, we compare the performance of our two machine learning methods in predicting these three defect types.## III. TIME SERIES REPRESENTATION FOR DEFECT DETECTIONAn important step in any machine learning method is finding a representation of the original measurements that supports discrimination between different classes. For instance: the mean of the measurement signal of a wheel with or without a flat spot coincide if the weight of the axle is t", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 20, "year": "2008"}}
{"text": "ent classes. For instance: the mean of the measurement signal of a wheel with or without a flat spot coincide if the weight of the axle is the same and the defect perfectly hits a sensor. The standard deviation on the other hand differs significantly, since the force exerted on the track is much higher for a wheel with the flat spot than for non-defective wheels. For other types of defects like shelling this observation does not hold, as the variance of the measured force does not significantly differ from a non-defective wheel, but there is a clear difference in higher frequency bands of the measurement, c.f. Fig. 4.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 21, "year": "2008"}}
{"text": " significantly differ from a non-defective wheel, but there is a clear difference in higher frequency bands of the measurement, c.f. Fig. 4. These observations suggest to decompose the signal by a multiscale wavelet analysis in order to extract indicative frequency features for time series data.Signal<br>C 1<br>C 2<br>C 3<br>**----- End of picture text -----**<br>## A. Wavelet TransformThe Discrete Wavelet Transform (DWT) decomposes a signal over an orthonormal basis of dilated and transformed wavelets :where ψ denotes mother wavelet, j and k the scale and shift parameters.The orthogonal wavelets given by definition (1) at different scales 2 [j] resolve the original signal at different resol", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 22, "year": "2008"}}
{"text": "nd shift parameters.The orthogonal wavelets given by definition (1) at different scales 2 [j] resolve the original signal at different resolutions. The DWT can thus be employed to construct a multiresolution signal approximation . An equivalent way of calculating the DWT is by passing the original signal through a series of appropriate high-pass and low-pass filters and sub-sampling operations, where at each level the output of the high-pass filter is stored as the detail coefficients for that level and the output of the low-pass filter is decomposed further at the next level until level T = log( n ) is reached, where n is the length of the original signal.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 23, "year": "2008"}}
{"text": "e low-pass filter is decomposed further at the next level until level T = log( n ) is reached, where n is the length of the original signal. If the high-pass and low-pass filters in this filter bank are derived from the child wavelets in Equation 1, the detail coefficients (C1, . . . , C T ) correspond exactly to the wavelet coefficients.The wavelet transform has been extensively used in fields ranging from biomedical signal processing , geosciences  to image compression . Since weight measurement signals and the defect effects on the signal are both localized in time and frequency the wavelet transform explicitly encodes this local perturbation and, therefore, has an advantage over the four", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 24, "year": "2008"}}
{"text": "alized in time and frequency the wavelet transform explicitly encodes this local perturbation and, therefore, has an advantage over the fourier transform in our application. The weight measurement signals also show a self-similar behavior which suggests thewavelet transformation as an adapted set of basis functions with approximately the same amount of power per frequency band.## B. Wavelet Features for Defect DetectionTo extract features from the measurement signals of the wheels, we first compute the wavelet decomposition of each signal. Each time series is now represented by the distributions of the wavelet coefficients at the different levels of the multiscale decomposition.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 25, "year": "2008"}}
{"text": "ach time series is now represented by the distributions of the wavelet coefficients at the different levels of the multiscale decomposition. To represent the distribution of the coefficients, n moments of the empirical distribution of the coefficients are computed. This representation captures higher order behaviour while still maintaining invariance to shift or scale of the defects as measured by the sensors. The procedure is summarized by Algorithm 1 and the function to compute the central moments is given below by Equation 2, where the average is used as the first moment.As explained in Section II-A, we observe eight signals for each wheel that we want to classify.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 26, "year": "2008"}}
{"text": "here the average is used as the first moment.As explained in Section II-A, we observe eight signals for each wheel that we want to classify. To compute features for one wheel, we first concatenate the measurements of all the sensors and then compute the wavelet features on this single time series. When we are processing localized defects, like a flat spot, that are observable as a change in vertical force on one sensor, the specific information, which sensor has observed a defect, does not play a role due to the scale invariance of our feature construction method. For each sensor, the measurement signal can be divided into the regions of no load, raising slope, load measurement window and fa", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 27, "year": "2008"}}
{"text": "on method. For each sensor, the measurement signal can be divided into the regions of no load, raising slope, load measurement window and falling slope. Even though the load measurement window is relatively small we can still observe wheel defects that manifest themselves in one of the slopes or during the no load phase before and after the load measurement. To capture this information, a window of size three times the measurement window is used for feature construction. In all our experiments we use the Daubechies-5 wavelet family as basis functions .## C. Load Normalized Featureswavelet features for each sensor separately.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 28, "year": "2008"}}
{"text": "iments we use the Daubechies-5 wavelet family as basis functions .## C. Load Normalized Featureswavelet features for each sensor separately. Whereas the feature construction based on the full signal pursued the strategy to capture as much information as possible, the goal here is to construct features that are normalized with respect to the load measurement.To this end, we first subtract an idealized measurement curve from the signal of each sensor and then compute wavelet features with Algorithm 1 on the difference. Additionally we add the mean squared error of the signal to the measurement template as a feature per sensor.## D.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 29, "year": "2008"}}
{"text": "ithm 1 on the difference. Additionally we add the mean squared error of the signal to the measurement template as a feature per sensor.## D. Measurement SiteEach wheel load checkpoint exhibits different physical characteristics due to small differences in the ground below the tracks and the curvature of the track before the checkpoint. These characteristics change the wheel load measurement. Small unevenness in the tracks also manifest themselves as noise or small bumps in the signal. Therefore, we add the site of the wheel load checkpoint as additional feature to enable different predictions based on the origin of the measurement site.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 30, "year": "2008"}}
{"text": "add the site of the wheel load checkpoint as additional feature to enable different predictions based on the origin of the measurement site. We encode this information as a unary code or a onehot vector, where every dimension represents a site and is 1 only for measurements from that site. When in the future a new measurement site would be built on the railway network, training data for the new site would need to be collected.## E. LoadA train with different load, but the same waggons results in different wheel measurements for the same defect types, since the weight of the train plays a significant role how the defect exerts its pressure on the sensors.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 31, "year": "2008"}}
{"text": "rements for the same defect types, since the weight of the train plays a significant role how the defect exerts its pressure on the sensors. Another important reason to add information about the load to the feature set arises from the following observation: certain defect classes like nonroundness mostly change the average of a sensor reading, but only marginally affect higher order information. An oval wheel for instance will result in higher load measured by some of the sensors and lower load by others, but will not be detected as a defect wheel by individual load normalized measurements. The mean load of all the sensors, standard deviation over the mean load per sensor and the mean load f", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 32, "year": "2008"}}
{"text": "ividual load normalized measurements. The mean load of all the sensors, standard deviation over the mean load per sensor and the mean load for each sensor are added to the feature set.## IV. AUTOMATIC REPRESENTATION LEARNINGAn alternative to predefined feature representations are provided by deep neural networks that learn the features from data in a task specific way to maximize correct classification. In this section we introduce a learning method to automatically infer a representation of the measurements for the classification of wheel defects based on deep artificial neural network models (DNN). These models have gained considerable popularity in recent years, mostly due to their succes", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 33, "year": "2008"}}
{"text": "on deep artificial neural network models (DNN). These models have gained considerable popularity in recent years, mostly due to their success in image classification and segmentation tasks , in speech recognition  and quite recently in reinforcement learning for playing Go .DNN for wheel defect detection alleviates the burden of the modeller to manually construct features and allows to learn representations from time series directly. Another benefit isthe flexibility that comes with designing decision functions as stacked activation layers. This flexibility allows us to design a network specifically for certain defect types.## A.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 34, "year": "2008"}}
{"text": " decision functions as stacked activation layers. This flexibility allows us to design a network specifically for certain defect types.## A. 2-Dimensional Time Series RepresentationMotivated by the success of convolutional neural networks on image classification tasks  we propose the use of 2D representations of the measurement signals for wheel defect detection. Recently Gramian Angular Fields (GAF) have been proposed  as a 2-dimensional encoding of time series data. This representation has been shown to capture cross-temporal dependencies and to enhance classification performance when used as input to a convolution network.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 35, "year": "2008"}}
{"text": "has been shown to capture cross-temporal dependencies and to enhance classification performance when used as input to a convolution network. A GAF is constructed by first transforming the time series to polar coordinates and then computing trigonometric sums between all points .As a second 2D representation we also considered transforming the time series into the image of its 2D graph. This procedure is motivated by the fact that a human expert would also look at such a two-dimensional representation to classify wheel defects. The addition of the value of the signal as the second dimension allows the network to learn different filters for different values of the signal at the same point in t", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 36, "year": "2008"}}
{"text": "f the signal as the second dimension allows the network to learn different filters for different values of the signal at the same point in time (the first dimension). The procedure is summarized in Algorithm 2.**Input:** X = ( Xt )1 ≤t≤N : time series. **Input:** r > 0: resolution. **Input:** [ Vmin, Vmax ]: window. 1: h =  Vmax−r Vmin  2: M = **0** h×N 3: X = X − Vmin 4: **for** t = 1 . . . N **do** 5: M⌈ Xrt[⌉][,t][ = 1] 6: **end for** 7: **for** m = 1 . . . N − 1 **do** 8: Set all entries touching the segment [ M⌈ Xrm[⌉][,m][, M][] [Xm] r[+]  ,m +1[]] to 1, drawing a line segment between the two points. 9: **end for Output:** M : 2D graph of time series X .## B.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 37, "year": "2008"}}
{"text": "[, M][] [Xm] r[+]  ,m +1[]] to 1, drawing a line segment between the two points. 9: **end for Output:** M : 2D graph of time series X .## B. DNN Network ArchitectureWe use a Convolutional Neural Network (CNN) based architecture to automatically extract the discriminating features. Here, we considered the 8 signals of the WLC as different channels. Our networks are composed of two modules: the mono channel feature extracting layers and cross channel feature extracting layers respectively from bottom (input layer) to top (classification layer). The mono channel feature extracting layers take each channel independently and compute high level features in parallel that can then be processed by th", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 38, "year": "2008"}}
{"text": "annel feature extracting layers take each channel independently and compute high level features in parallel that can then be processed by the cross channel feature extracting layers. Furthermore, the weight of the mono channel feature extracting layers are shared across all channels, allowing it to learn from all channels at once.This approach is both computationally efficient, and also well suited for the data set. Since each channel represents a load measurement of the wheel from one sensor of the WLC the network learns features from the signals and also a relationship between the signals.1) Mono channel feature extracting layer: This module is a traditional CNN, composed of a sequence of", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 39, "year": "2008"}}
{"text": "so a relationship between the signals.1) Mono channel feature extracting layer: This module is a traditional CNN, composed of a sequence of convolutional layers, eventually followed by a fully connected layer:a) Convolutional layer: A convolutional layer is a combination of a number of filtering layers, each followed by a non-linearity and a pooling layer. The settings chosen for each of these layers are specified below. The filtering layer outputs convolutional products of the input by learnable filters with a fixed receptive field. Every filter layer is followed by an activation function. We use a Parametric Rectified Linear Unit ( PReLU ), as it better back-propagates the gradient compare", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 40, "year": "2008"}}
{"text": "s followed by an activation function. We use a Parametric Rectified Linear Unit ( PReLU ), as it better back-propagates the gradient compared to the tangent hyperbolic or sigmoid functions, which can easily saturate. The PReLU non-linearity also prevents neurones from “dying out” as can be the case for the popular ReLU units, by introducing a learnable non-zero slope to the negative side of the input.## where a is an adaptable parameter.The pooling layers reduce the resolution of the input time series and the learned features at each layer of the deep neural network. This max-pooling allows the classification to be robust to small variations of learned features at each layer.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 41, "year": "2008"}}
{"text": "r of the deep neural network. This max-pooling allows the classification to be robust to small variations of learned features at each layer. In all of our convolutional layers, we used a pooling layer with filters of size 2 × 2 applied with downsampling ratio of two, taking the maximum value among the four pixels in its receptive field.b) Fully connected layer: Neurons in a fully connected layer have full connections to all units in the previous layer. The layer outputs biased linear combination of its input, followed by a non-linearity. As a non-linearity we used the hyperbolic tangent function (tanh).a) Cyclic Permutation Network: The cyclic permutation network (Fig.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 42, "year": "2008"}}
{"text": "arity. As a non-linearity we used the hyperbolic tangent function (tanh).a) Cyclic Permutation Network: The cyclic permutation network (Fig. 5) is designed to learn cross-sensor features invariant to a cyclic permutation of the eight recordings. Depending on its phase, a given wheel can generate a set of possible recordings, which is approximately stable by cyclic permutation of the eight recordings. This network architecture serves the purpose to encode this characteristic of cyclic invariance. The network works in the following way:- 1) The Cyclic Permutation Network sits on top of the Mono channel feature extracting layers.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 43, "year": "2008"}}
{"text": "iance. The network works in the following way:- 1) The Cyclic Permutation Network sits on top of the Mono channel feature extracting layers. It takes as input the set of high level features of each channel computed independently by the weight shared CNN (represented as a dashed red box right of the signal in Fig. 5).- 2) The network then distributes the set of 8 feature vectors vi (the colored vertical bars in Fig. 5) across 8 permutation channels (the stack of colored horizontal bars in Fig. 5), one for each possible cyclic permutation of the feature vectors. Each permutation channel concatenates the feature vectors following the order of its specific cyclicNormal<br>Min<br>Defect<br>Max<br", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 44, "year": "2008"}}
{"text": "ctors. Each permutation channel concatenates the feature vectors following the order of its specific cyclicNormal<br>Min<br>Defect<br>Max<br>**----- End of picture text -----**<br>- permutation. Note the distinction between “channels” and “permutation channels”, as the former refers to a specific sensor recording, while the latter refers to a permutation of the input channels, and contains the high level features of all initial channels.- 3) Afterwards, the concatenated vector within each permutation channel is fed into a sequence of fully connected layers that extracts cross channel features and outputs the classification probability for the respective cyclic permutation (The blue circles i", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 45, "year": "2008"}}
{"text": "rs that extracts cross channel features and outputs the classification probability for the respective cyclic permutation (The blue circles in Fig. 5).- 4) Finally, the multiple log-likelihoods (one for each permutation channel) are combined by returning the maximal log-likelihood for the defect class and the minimal loglikelihood for the non-defective class (The green dashed box in Fig. 5).Formally, given a set of 8 feature vectors, ( vi )1 ≤i≤ 8, for a wheel the cyclic permutation network computes the probability of defect P[D] as:where P is the set of all possible cyclic permutations of the numbers [1 , 8], f ( · ) is the function performed by the fully connected layers and ∥ is the concat", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 46, "year": "2008"}}
{"text": "all possible cyclic permutations of the numbers [1 , 8], f ( · ) is the function performed by the fully connected layers and ∥ is the concatenation operator.b) Defect Detection Network for Flat Spots: For tasks like flat spot detection, it is not necessary to learn complex cross channel features. Since a flat spot is a discrete defect and usually manifests itself only in one sensor reading, the Multiple Instance Learning (MIL) setting  is appropriate. In this setting a wheel is considered defective when at least one of the sensor readings is predicted defective. The Defect Detection Network encodes this idea by reducing the crossWeight-shared convolutional networks<br>Input from 8 sensors<br", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 47, "year": "2008"}}
{"text": "fective. The Defect Detection Network encodes this idea by reducing the crossWeight-shared convolutional networks<br>Input from 8 sensors<br>MinMax Layer<br>Min PNormal<br>Max PDefect<br>**----- End of picture text -----**<br>channel feature to the indicator function of whether a defect has been detected in one of the channels:- 1) It takes as input the set of classification probabilities of each channel computed independently by the Mono channel feature extracting layer.- 2) It combines the multiple log-likelihoods by returning the maximal log-likelihood for the defect class and the minimal log-likelihood for the non-defective class.Given a set of s log-likelihoods for binary classification", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 48, "year": "2008"}}
{"text": "d for the defect class and the minimal log-likelihood for the non-defective class.Given a set of s log-likelihoods for binary classification from s sensors x = ( Pi[D][, P] i[ N][)] [≤][i][≤][s][, where] [ P][ D] i is the likelihood for defect and Pi[N] for non-defect from sensor i . Since Pi[N] = 1 − Pi[D] and 0 ≤ Pi[D] ≤ 1:In Fig.  we depict the structure of the DNN that we use to train a model for the detection of flat spots.We call the last layer MIL-Layer. It makes sure that if one measurement of the wheel captures the defect, the probability of the wheel having a defect is high. If defects are not “seen” by any sensor this probability will be low.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 49, "year": "2008"}}
{"text": "ures the defect, the probability of the wheel having a defect is high. If defects are not “seen” by any sensor this probability will be low. Moreover, when training with defective wheels, only the error of the channel with the highest defect probability is backpropagated, thus preventing the Mono channel feature extracting layer to try to learn features for defective signals on signals that show no defect.The MIL setting was already used for the SVM based MIL flat spot classifier in Krummenacher, Ong, and Buhmann .## C. Top Layer Features learned by the DNNIn this section we look at the features learned by the DNN and compare the filters learned by the network on the 1- dimensional or 2-dime", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 50, "year": "2008"}}
{"text": "DNNIn this section we look at the features learned by the DNN and compare the filters learned by the network on the 1- dimensional or 2-dimensional time series representation. The results in this section were obtained by training on data set 2  and defect type flat spot.Examples of top-layer filters learned by the DNN directly on the 1-dimensional time series, as well as the features extracted  n Fig. 7. We  network has been trained to detect a short quick oscillation in the time series. The extracted features on the defective input clearly shows the successful training of the model in detecting defect regions.## V.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 51, "year": "2008"}}
{"text": "e series. The extracted features on the defective input clearly shows the successful training of the model in detecting defect regions.## V. CLASSIFICATION OF WHEEL DEFECTSDetection and classification of wheel defects amounts to infer from a vertical force measurement **x** of a wheel if a · wheel is defective or not. Mathematically, a function f ( ) either encode the binary information, that a defect is present or absent, or its defect class when we can differentiate the defect category. To achieve this goal we use sets of measurementsof wheels to train decision functions for certain defect types and for non-defective wheels.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 52, "year": "2008"}}
{"text": "To achieve this goal we use sets of measurementsof wheels to train decision functions for certain defect types and for non-defective wheels. We then use this training set of measurements and labels (the type of defect) to automatically find a function that is expected to predict the defects of wheels not seen during training accurately.## A. Support Vector MachineOne of the most popular models to find such a function are Support Vector Machines (SVM) . A SVM finds a linear function parameterized by the vector **w** that maximally separates the two classes during training. It achieves this separation by maximizing the margin between the points of the two classes in feature space, or equivalen", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 53, "year": "2008"}}
{"text": "s during training. It achieves this separation by maximizing the margin between the points of the two classes in feature space, or equivalently by minimizing the regularized empirical riskwhere we minimize the empirical risk over the parameters ( **w** , b ), that encode the hyperplane separating the two classes. yi ∈ ( − 1 , +1) is the label (class membership) of the i[th] example in the training set, **x** i denotes the feature vector of the i[th] measurements and max(0 , 1 − z ) is the hinge loss. Measurements of a new wheel **x** can now be classified with the following decision rule:This decision rule (7) expresses its data dependence only by a scalar product between weights **w** and t", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 54, "year": "2008"}}
{"text": "d with the following decision rule:This decision rule (7) expresses its data dependence only by a scalar product between weights **w** and the feature vector **x** . Therefore, we can model non-linear decision functions by replacing the scalar product with a kernel. A convenient choice is a Gaussian radial basis kernel function of the form k ( **x** i, **x** j ) = exp( −γ ∥ **x** i − **x** j∥ ) on the feature vectors **x** i, **x** j . We can now express the minimization problem above (Equation 6) in the dual and employ the kernel trick to learn parameters αi and get the new classification ruleTo determine the optimal parameters for regularization λ and scale γ we maximize accuracy on cross-", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 55, "year": "2008"}}
{"text": "rs αi and get the new classification ruleTo determine the optimal parameters for regularization λ and scale γ we maximize accuracy on cross-validation folds.## B. Classification with DNNIf we replace the hinge loss function in Equation (6) in the previous section with the logistic loss function log 1 + exp( −yi **w** [⊤] **x** ) we get regularized logistic regression. This optimization problem has the advantage that optimization algorithms estimate probabilities of the class likelihoods in addition to the binary labels. Using the softmax function instead of the logistic loss this benefit can be generalized to an arbitrary number of classes.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 56, "year": "2008"}}
{"text": "he binary labels. Using the softmax function instead of the logistic loss this benefit can be generalized to an arbitrary number of classes. We will use these probability estimates through a SoftMax-layer in our DNN to combine the output of multiple classifiers for different measurements of the same wheel.For a given input and C classes, its log-likelihood for belonging to class i equalswhere ( vi )1 ≤i≤C are the top-layer features of the network. The soft-max function above is not only used for DNNs but also in many multiclass classification methods, for instance for logistic regression or in dynamical system estimation with multiple model adaptive estimation (MMAE)Unlike the previous secti", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 57, "year": "2008"}}
{"text": "r instance for logistic regression or in dynamical system estimation with multiple model adaptive estimation (MMAE)Unlike the previous section, where the classification function f ( · ) was modeled as a linear function in a Hilbert space, that takes a fixed representation of the measurements, DNNs model this function as a hierarchical structure (layers) of linear combinations and activation functions (non-linearities) directly on the time series of the measurement .## VI. DATA SETS AND MODELSTwo data sets from different sources are assembled to evaluate the performance of different methods for wheel defect detection and classification and to train various classifiers.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 58, "year": "2008"}}
{"text": "e assembled to evaluate the performance of different methods for wheel defect detection and classification and to train various classifiers. For both data sets the signals that we use to predict a wheel defect are measured by the wheel load checkpoint . The annotations or labels that provide the information about the defectiveness and defect class of a wheel are collected from different sources. These data sets contain information about different types of defects as described in the following. We also describe what models and features we will use for the respective data sets in this section.## A. Models and FeaturesOn the first data set we compare the Wavelet-SVM with benchmark flat spot pre", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 59, "year": "2008"}}
{"text": " respective data sets in this section.## A. Models and FeaturesOn the first data set we compare the Wavelet-SVM with benchmark flat spot prediction methods. We show that it greatly outperforms prior art based on thresholding the dynamical coefficient (Eq.  below) and also on multiple instance learning with dynamic time warping.The second data set serves to demonstrate that the WaveletSVM can accurately classify all three defect types. We also compare the performance of the deep learning models on different time series representations by showing that the cyclic permutation network outperforms the simpler neural networks and also the Wavelet-SVM for non-roundness.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 60, "year": "2008"}}
{"text": "entations by showing that the cyclic permutation network outperforms the simpler neural networks and also the Wavelet-SVM for non-roundness. For flat spots, the neural network with features learned on the 2D time series representation also outperforms the Wavelet-SVM.We use different models and features for different defect classes, as this allows us to model network structure and feature construction adaptively to the effects the defects have on the measurements. Thus the problem differs from standard multi-class classification where one model predicts a vector of class probabilities over all classes. Instead we are looking at independent binary classification tasks per defect class, where", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 61, "year": "2008"}}
{"text": "a vector of class probabilities over all classes. Instead we are looking at independent binary classification tasks per defect class, where the task is to distinguish between one defect type and nondefective. This enables clear comparison between the different models.As there are no known methods to predict non-roundness or shelling we compare to baseline methods on a data set with flat spots (data set 1). To evaluate our Wavelet-SVM on nonroundness and shelling as well we use data set 2 to estimate classification performance on all three defect classes. We have proposed two different DNNs for defect detection in Sec. IV-B: the cyclic permutation network (cyclic DNN) and the MILDNN.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 62, "year": "2008"}}
{"text": " classes. We have proposed two different DNNs for defect detection in Sec. IV-B: the cyclic permutation network (cyclic DNN) and the MILDNN. We use the cyclic DNN to predict non-roundness asthis is a non-discrete defect type with large-scale effects. We take the maximum probability of defectiveness over multiple inputs. As the region of the wheel that rolls over the first sensor is arbitrary we want to be able to be invariant to a specific way of shifting the sensors. Thanks to the symmetric way and the distances at which the sensors are installed we can look at cyclic shifts of the concatenated signal of all sensors to simulate different scenarios.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 63, "year": "2008"}}
{"text": "s at which the sensors are installed we can look at cyclic shifts of the concatenated signal of all sensors to simulate different scenarios. The DNN trained to learn these cyclic shift invariant features is described in Section IV-B2a. The MIL-DNN is used to predict flat spot on data set 2 as the multiple instance learning setting lends itself nicely to this defect type as explained in Sec. IV-B2b.## B. Data Set 1: Calibration RunTo acquire a first training data set for flat spots, two wheels on different wagons were artificially damaged. The wagons were then added to a calibration train that was run over different measurement sites with different velocities and from both directions to calib", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 64, "year": "2008"}}
{"text": " then added to a calibration train that was run over different measurement sites with different velocities and from both directions to calibrate the wheel load check points. This resulted in 1600 measurements, 50% of which are from a wheel with a flat spot.We also consider another method to detect flat spots in this data set, that is not based on machine learning. It is a conservative threshold on the dynamic coefficient: a general measure of spread within one time series. For each sensor this coefficient is given bywhere max and ¯ **x** refer to the maximum and average value of a sequence of measurements **x** , respectively.## C.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 65, "year": "2008"}}
{"text": "coefficient is given bywhere max and ¯ **x** refer to the maximum and average value of a sequence of measurements **x** , respectively.## C. Data Set 2: Reprofile EventsTo generate data for training and testing a classifier that can predict additional types of wheel defects, we aggregated the time and date of reprofile events and linked them to railway wagons. We used two sources for these events: the protocols of repair workshops of freight trains and the regular maintenance measurements of passenger trains. These were annotated with a defect class by an expert before re-profiling the defective wheels. We then categorized measurements of the wheel load checkpoints of the same wagons around", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 66, "year": "2008"}}
{"text": "n expert before re-profiling the defective wheels. We then categorized measurements of the wheel load checkpoints of the same wagons around the date of re-profiling. Measurements up to a week before re-profiling were considered defective (according to the class label given by the expert), while measurements up to a week after reprofiling were considered defect free. Using this procedure we were able to obtain a large data set of annotated measurements from wheels of different defect classes over the span of multiple years. 1836 measurements are evaluated for flat spot detection, where 588 cases are classified as defective.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 67, "year": "2008"}}
{"text": "asses over the span of multiple years. 1836 measurements are evaluated for flat spot detection, where 588 cases are classified as defective. For shelling, we received 6070 measurements, with 2678 being defective. For the non-roundness defect class, 688 cases out of 920 measurements are defective.## VII. EXPERIMENTAL RESULTSFor performance evaluation of the methods we compute three metrics: accuracy, precision and recall. Whereas accuracygives the total fraction of correctly classified wheels, precision measures the fraction of correctly predicted defects out of all predicted defects and recall the fraction of correctly predicted defects out of all defects .## A.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 68, "year": "2008"}}
{"text": "of correctly predicted defects out of all predicted defects and recall the fraction of correctly predicted defects out of all defects .## A. Model Selection and EvaluationFor all the experiments in this section the performance shown is computed on a test set that was not used for training or model/parameter selection. To make the evaluation robust against chance we repeat each experiment multiple times on new random train/test splits and report average and standard deviation over these repetitions. For data set 1 we only report the average as the standard deviation was not reported for the benchmark method. For data set 1 50% of the data is hold out for testing, for data set 2 20%.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 69, "year": "2008"}}
{"text": "he standard deviation was not reported for the benchmark method. For data set 1 50% of the data is hold out for testing, for data set 2 20%. For the Wavelet-SVM the average performance is computed over 10 repetitions, for the DNNs over three repetitions. Using less experiments for the DNNs is due to computational reasons and justified by the low standard deviation over repetitions in all experiments < = 2%. For the Wavelet-SVM three-fold cross-validation is performed on the training set to find the optimal hyper-parameters of the SVM and the Gaussian rbf kernel with grid-search on an exponentially spaced grid.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 70, "year": "2008"}}
{"text": "e training set to find the optimal hyper-parameters of the SVM and the Gaussian rbf kernel with grid-search on an exponentially spaced grid. For the DNN 10% of the training set were set aside as a validation set to benchmark performance online and decide on when to stop training.As the class proportions for data set 2 are not balanced (c.f. Sec VII-C) training and evaluating the classifiers directly on this data would lead to bias and higher classification probability for the over-represented class. It would also make judging accuracy and comparing the methods and data sets hard, as the baseline for random chance would not be 50%.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 71, "year": "2008"}}
{"text": "class. It would also make judging accuracy and comparing the methods and data sets hard, as the baseline for random chance would not be 50%. Therefore as a first step in all experiments we re-balance the class proportions of the data sets by randomly over-sampling the smaller class through sampling with replacement. While balanced data sets are useful for comparing methods and data sets, in a real-world setting the true proportion of the classes is important and mistakes for different types of error might have different cost. Therefore we recommend to give class probability estimates for each class when implementing such a system and then adapting a threshold for raising an alarm iteratively", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 72, "year": "2008"}}
{"text": "ve class probability estimates for each class when implementing such a system and then adapting a threshold for raising an alarm iteratively based on the test performance of the system.Table III: Test set performance of the deep models on flat spots in data set 2.Table IV: Test set performance of the deep models on nonroundness in data set 2.## B. Data Set 1\nIn a study prior to this publication , this data set was used to empirically demonstrate the effectiveness of a new algorithm for MIL . Krummenacher, Ong, and Buhmann  beat state-of-the art MIL algorithms on this data set and get a classification accuracy of 70% with ellipsoidal multiple instance learning (eMIL).", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 73, "year": "2008"}}
{"text": "tate-of-the art MIL algorithms on this data set and get a classification accuracy of 70% with ellipsoidal multiple instance learning (eMIL). In this study features based on the Global Alignment (GA) kernel for time-series  were used.Using the features described in Section III with a SVM  we were able to improve accuracy to 92% .With the current operational threshold of θ = 3 on the maximal dynamic coefficient (Eq. 10) an accuracy of 60% is achieved. This is relatively low, as with random guessing already 50% accuracy could be achieved. It is thus important to note that the precision of this method is perfect with 100% of reported wheels being defective.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 74, "year": "2008"}}
{"text": "y could be achieved. It is thus important to note that the precision of this method is perfect with 100% of reported wheels being defective. So even though the method misses defective wheels it never raises a false alarm.## C. Data Set 2 - SVMEquipped with our general method of constructing features from multiple wheel vertical force measurements  and learning a classifier from them  we are now ready to predict other types of wheel defects as well. We also evaluate the DNN based method  in this section.The SVM classifier  are trained on the labels obtained by this method for the defect types flat spot, shelling and non-roundness.In Table II the performance on the reserved test set is reporte", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 75, "year": "2008"}}
{"text": "ed by this method for the defect types flat spot, shelling and non-roundness.In Table II the performance on the reserved test set is reported for each defect type including standard deviation over the permutations. The performance on shelling is the best out of the three defect types. This observation can be explained by the fact that the training set for this defect type was by far the largest, so we were able to train a classifier with higher accuracy. This defect type also affects the wheel globally, so it is harder to miss for the sensors than a flat spot. To improve the performance on flat spot and non-roundness we trained custom deep neural networks and give the results in the next sec", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 76, "year": "2008"}}
{"text": " spot. To improve the performance on flat spot and non-roundness we trained custom deep neural networks and give the results in the next section.For the defect type non-roundness, the load normalized features based on the load observed by individual sensors (c.f. Section III) substantially contributed to an increase in accuracy. This effect can be explained by the observation that wheel non-roundness errors do not cause a large variation on the within measurement time series since they are a nondiscrete type of wheel defects. They do introduce variations between the different measurements per wheel on the other hand and so features based on averages per measurement sequence are important.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 77, "year": "2008"}}
{"text": "ons between the different measurements per wheel on the other hand and so features based on averages per measurement sequence are important. We will improve the classification performance for flat spot and non-roundness in the next section by using a custom deep neural network (DNN) that is cyclicshift invariant for classification of these defect types.One complication of this data set arises from the lack of knowledge if the wagon passes the wheel load checkpoint with the same orientation as the wheels were annotated in the workshop. This lack of information leads to uncertain labels for the class of defective wheels, as not all wheels on a wagon necessarily share a defect.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 78, "year": "2008"}}
{"text": "is lack of information leads to uncertain labels for the class of defective wheels, as not all wheels on a wagon necessarily share a defect. For the class of nondefective wheels this uncertainty does not pose a problem, since all wheels of a wagon are re-profiled and therefore are non-defective in our data set. We deal with this problem by adding both possible orientations of each wagon to the data set for the defective class of wheels. This augmentation of the data set introduces additional noise to the learning problem during training as non-defective wheels might be labeled defective. Nonetheless, we are able to train classifiers with high accuracy for all three types of defects (flat spo", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 79, "year": "2008"}}
{"text": "wheels might be labeled defective. Nonetheless, we are able to train classifiers with high accuracy for all three types of defects (flat spot, non-roundness, shelling) based on data generated from this source. Since during testing the same uncertainty exists and actually non-defective wheels might have a defect class assigned the error rate of the classifier appears to be over-reported . Therefore the numbers reported in Table II and in the next section are a lower bound on the performance of the classifier.## D. Data Set 2 - Deep LearningUsing the same data set as in the previous section we evaluate the deep learning method  on the two defect types flat spot and non-roundness.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 80, "year": "2008"}}
{"text": "sing the same data set as in the previous section we evaluate the deep learning method  on the two defect types flat spot and non-roundness. To simplify the experiments we do not include additional features like speed, measurement site or template fit, but only consider the wheel vertical force measurements from the WLC sensors. Therefore, the performance of the SVM is slightly worse compared to the previous section.To compute the 2D image of the time series we proceeded as following: first, the recording from each of the 8 channels have been preprocessed via PAA , with bin number N = 156. The GAF encoding as well as the 2D graph were computed for each channels (we took the following paramet", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 81, "year": "2008"}}
{"text": "d via PAA , with bin number N = 156. The GAF encoding as well as the 2D graph were computed for each channels (we took the following parameters for the 2D graph: Vmin = − 4 , Vmax = 6 as the window captures more than 99 . 9% of all the values, and r = [V][max][−] N[V min] = 10 N[to generate square pictures of size] [ N][ ×][ N][). Finally, the] picture size was further reduced by averaging every 2 × 2 nonoverlapping pixels for computational reasons, resulting in 8 channels of size 78 × 78 for both GAF and 2D graph encoding.To prevent overfitting to the training set and to enable the model to explore a larger parameter space, we augmented thedata by adding Gaussian noise and by randomly shift", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 82, "year": "2008"}}
{"text": "raining set and to enable the model to explore a larger parameter space, we augmented thedata by adding Gaussian noise and by randomly shifting and re-scaling the time series before applying image transformations.We applied dropout regularization  on all the fully connected layers. To further improve generalization, we added an additional ℓ 2 weight regularization penalty term in the cost function (“weight decay”) to encourage smooth solutions by favouring small weights. We have employed stochastic gradient descent with Nesterov Momentum  to accelerate convergence. The learning rate was set to decay inversely proportional to the number of epochs.1) Flat Spots: In Table III we compare the per", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 83, "year": "2008"}}
{"text": "onvergence. The learning rate was set to decay inversely proportional to the number of epochs.1) Flat Spots: In Table III we compare the performance of the different DNN models and the Wavelet-SVM. The only deep model that is able to out-perform the accuracy of the Wavelet-SVM is based on the 2D image of the time series. All of the deep models have smaller standard deviation and higher precision.2) Non-roundness: In Table IV we compare the performance of the cyclic DNN with the DNN used for flat spot prediction (Deep MIL), a DNN that is trained on the concatenation of all the sensors (Deep Concat) and the Wavelet-SVM.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 84, "year": "2008"}}
{"text": "N used for flat spot prediction (Deep MIL), a DNN that is trained on the concatenation of all the sensors (Deep Concat) and the Wavelet-SVM. Remember that the MIL-DNN used for flat spot prediction is trained by looking at the time series of each sensor individually and computing the loss on the sensor with highest probability of observing the defect. The performance of the different methods on the test set shows that MIL is an inadequate model for this type of defect since a wheel with a non-roundness defect can not be reliably identified on the basis of only one sensor measurement. This non-local behavior is in contrast to the challenge of predicting flat spot.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 85, "year": "2008"}}
{"text": "bly identified on the basis of only one sensor measurement. This non-local behavior is in contrast to the challenge of predicting flat spot. Concatenating the sensors as is and not looking at the possible cyclic permutations resulted in training set accuracy similar to the cyclic shift network, but performance on the test set is significantly worse . Intuitively ignoring the permutations leads to overfitting as the measurements in the test set might be shifted arbitrarily.In comparison with the Wavelet-SVM the cyclic DNN shows higher accuracy and precision and reduced variance. Unlike the DNN for flat spot we only trained the cyclic DNN for non-roundness directly on the 1D time series, as th", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 86, "year": "2008"}}
{"text": "on and reduced variance. Unlike the DNN for flat spot we only trained the cyclic DNN for non-roundness directly on the 1D time series, as the increase in parameters due to the concatenation of measurements of the sensors prohibited efficient training of the model on the 2D representation.## VIII. CONCLUSIONWe have presented two machine learning methods for defect detection on railway train wheels. The methods analyse multiple time series of the vertical force of a wheel under operational speed and output if a wheel has a defect or not. Both methods are trained automatically on measurements gathered from defective and non-defective wheels.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 87, "year": "2008"}}
{"text": "put if a wheel has a defect or not. Both methods are trained automatically on measurements gathered from defective and non-defective wheels. The first method is based on novel general wavelet features for time series. The second method employs deep convolutional neural networks to automatically learn features from the time series directly or from a 2-dimensional representation. We design cyclic shift invariant artificial neural networks for the detection of wheel flats and non-round wheels that model the relationship betweenthe measurements inherent to these defects. To evaluate our methods we collect two data sets from different sources and demonstrate improved performance for predicting fl", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 88, "year": "2008"}}
{"text": "hese defects. To evaluate our methods we collect two data sets from different sources and demonstrate improved performance for predicting flat spot, shelling and non-roundness.The methods that were developed for this work are currently being implemented as part of the SBB wayside train monitoring system. To improve the quality of the training and test data RFID tags will be deployed to enable perfect association between defect labels and measurements. Further future work consists of integrating external features into the deep learning models, optimizing for precision and predicting severity scores for the defects.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 89, "year": "2008"}}
{"text": "sts of integrating external features into the deep learning models, optimizing for precision and predicting severity scores for the defects. For the prediction of severity scores we obtained promising preliminary results on regressing the flat spot length using support vector regression  and the wavelet features.", "metadata": {"doc_id": "krummenacher17sbb", "section": "ROOT", "level": 0, "chunk_id": 90, "year": "2008"}}
