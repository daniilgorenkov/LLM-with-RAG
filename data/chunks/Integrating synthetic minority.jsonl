{"text": "# Integrating synthetic minority oversampling and gradient boosting decision tree for bogie fault diagnosis in rail vehicles## Linlin Kou , Yong Qin , Xunjun Zhao and Yong Fu## AbstractBogies are critical components of a rail vehicle, which are important for the safe operation of rail transit. In this study, the authors analyzed the real vibration data of the bogies of a railway vehicle obtained from a Chinese subway company under four different operating conditions. The authors selected 15 feature indexes – that ranged from time-domain, energy, and entropy – as well as their correlations. The adaptive synthetic sampling approach–gradient boosting decision tree (ADASYN–GBDT) method is propos", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 0, "year": "2002"}}
{"text": "opy – as well as their correlations. The adaptive synthetic sampling approach–gradient boosting decision tree (ADASYN–GBDT) method is proposed for the bogie fault diagnosis. A comparison between ADASYN–GBDT and the three commonly used classifiers (K-nearest neighbor, support vector machine, and Gaussian naı¨ve Bayes), combined with random forest as the feature selection, was done under different test data sizes. A confusion matrix was used to evaluate those classifiers. In K-nearest neighbor, support vector machine, and Gaussian naı¨ve Bayes, the optimal features should be selected first, while the proposed method of this study does not need to select the optimal features.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 1, "year": "2002"}}
{"text": " Bayes, the optimal features should be selected first, while the proposed method of this study does not need to select the optimal features. K-nearest neighbor, support vector machine, and Gaussian naı¨ve Bayes produced inaccurate results in multi-class identification. It can be seen that the lowest false detection rates of the proposed ADASYN–GBDT model are 92.95% and 87.81% when proportion of the test dataset is 0.  and 0.9, respectively. In addition, the ADASYN–GBDT model has the ability to correctly identify a fault, which makes it more practical and suitable for use in railway operations. The entire process (training and testing) was finished in 2.4231 s and the detection procedure took", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 2, "year": "2002"}}
{"text": " suitable for use in railway operations. The entire process (training and testing) was finished in 2.4231 s and the detection procedure took 0.0027 s on average. The results show that the proposed ADASYN–GBDT method satisfied the requirements of real-time performance and accuracy for online fault detection. It might therefore aid in the fault detection of bogies.## IntroductionBogies are the main supportive parts in a rail vehicle, which are easily prone to failure. Bogie failures account for a substantial 21.1% based on the accumulation of failure data in a couple of years. Thus, it is important to perform an efficient fault diagnosis on bogies used in operational rail vehicles.There are ma", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 3, "year": "2002"}}
{"text": "in a couple of years. Thus, it is important to perform an efficient fault diagnosis on bogies used in operational rail vehicles.There are mainly two approaches for bogie fault diagnosis, i.e. model-driven approach and data-driven approach. The model-driven approach builds physical models to simulate the mechanical degradation and failure of bogies through changing model parameters. A rail vehicle bogie basically consists of a bogie frame, a wheel set, an axle box (with bearing), a driving device (only on EMU, contains motor, shaft coupling, gear box, etc.), a primary suspension mechanism (air spring, etc.), and so on.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 4, "year": "2002"}}
{"text": " driving device (only on EMU, contains motor, shaft coupling, gear box, etc.), a primary suspension mechanism (air spring, etc.), and so on. As illustratedin Figure 1, the complex structure and nonlinear coupled components make it quite difficult to develop such models. Therefore, the data-driven approach becomes more and more popular.The data-driven approach aims to derive fault information from condition monitoring data by machine learning methods. In this process, it is usually assumed that the instance number of all classes ina dataset is equal to each other. However, bogie field data show a typical class imbalance characteristic, i.e.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 5, "year": "2002"}}
{"text": "ance number of all classes ina dataset is equal to each other. However, bogie field data show a typical class imbalance characteristic, i.e. compared with data in normal condition, fault data are much smaller in size. Furthermore, in railway transit systems, the main attention is paid on fault conditions, which are the minority classes in the dataset, and misclassification of those classes comes at a high price. Therefore, the class imbalance problem has a great impact on the accuracy of data-driven bogie fault diagnosis. Another essential issue is the algorithm efficiency problem. Actual data are more complicated than the simulated ones.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 6, "year": "2002"}}
{"text": "ogie fault diagnosis. Another essential issue is the algorithm efficiency problem. Actual data are more complicated than the simulated ones. In order to obtain good results, high-dimensional feature space is commonly designed in bogie fault diagnosis. Dimensionality reduction method like principal component analysis (PCA) is necessary for rapid calculation. However, such procedure is also time consuming, which is contrary to the computational efficiency requirement. Finally, strong controllability is also an important factor in choosing the classifier for practical application. The working mechanism of the method and principle should be clear for controllable results.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 7, "year": "2002"}}
{"text": "oosing the classifier for practical application. The working mechanism of the method and principle should be clear for controllable results. Therefore, a controllable algorithm that can deal with class imbalance problem and handling high-dimensional features efficiently is urgent in need.To the authors’ best knowledge, research on using class imbalance data in rail vehicle fault diagnosis has not been fully documented to date. Many approaches have been developed to solve the class imbalance problem in other fields. Under-sampling techniques decrease the frequency of the majority class to balance data. However, it may be at the expense of losing important information of majority.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 8, "year": "2002"}}
{"text": "decrease the frequency of the majority class to balance data. However, it may be at the expense of losing important information of majority. Cost-sensitive methods use different cost matrices that describe thecosts for misclassifying any particular sample, instead of creating a balanced dataset. Some studies have shown that cost-sensitive methods perform better than sampling method, but they show a high degree of variance in the performance measures compared to the least expected cost over the evaluated datasets. Oversampling is the third approach to solve the class imbalance problem. The basic idea of oversampling methods is to increase the minority class samples by altering the samples in", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 9, "year": "2002"}}
{"text": "ve the class imbalance problem. The basic idea of oversampling methods is to increase the minority class samples by altering the samples in the dataset distribution. The synthetic minority oversampling technique (SMOTE) is a popular method proposed by Chawla et al. It constructed the synthetic minority samples through the interpolation between minority training data and its K-nearest neighborhoods. However, SMOTE would be problematic of categories overlap on newly generated samples, as it synthesized new sample of each existing data point without considering that the selected K-nearest neighborhoods were not in the same class of the current sample points.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 10, "year": "2002"}}
{"text": "h existing data point without considering that the selected K-nearest neighborhoods were not in the same class of the current sample points. Adaptive synthetic (ADASYN) sampling approach overcame the previous problem of SMOTE, and was also more efficient than those methods mentioned above. He et al. applied ADASYN to deal with the class imbalance problem to recognize abnormal heart sounds and got a sensitivity improvement of 58.6–84.4%. It can not only reduce the learning bias introduced by the original imbalance data distribution, but can also adaptively shift the decision boundary to focus on those difficultto-learn samples.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 11, "year": "2002"}}
{"text": "y the original imbalance data distribution, but can also adaptively shift the decision boundary to focus on those difficultto-learn samples. However, bogie fault diagnosis is a multi-class classification problem in which imbalance exists among more than two classes; no previous work has been done to address multi-class oversampling problem for ADASYN.Classification modeling plays an important role in bogie fault diagnosis. Many researches had been conducted on different classifiers for fault diagnosis of the rail vehicle. Hu et al. got a high accuracy of over 98% by the deep neural network with the cost of 6.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 12, "year": "2002"}}
{"text": "lassifiers for fault diagnosis of the rail vehicle. Hu et al. got a high accuracy of over 98% by the deep neural network with the cost of 6.  s on a high-performance computer, and the accuracy rate depends much on the sample size. A support vector machine (SVM) method got a relatively high recall value, with the calculation of 43 variables and feature selection procedure for braking system in high-speed trains. The permutation entropy of IMFs after EEMD and initial signals are calculated as multi-scale complexity measure feature vectors together with SVM to classify and identify the operating conditions of high-speed train bogies. But it worked on a binary system.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 13, "year": "2002"}}
{"text": "re vectors together with SVM to classify and identify the operating conditions of high-speed train bogies. But it worked on a binary system. To the best of our knowledge, most of them are expensive, time consuming or do not produce good results for a binary system. No previous research has studied the requirements of both less time computation and multi-class identification with consideration of imbalanced dataset in the fault diagnosis of bogies.Gradient boosting decision tree (GBDT) method is a powerful boosting method based on the decision tree model, originally derived by Friedman. It sequentially generates base models from a weighted version of the training data and searches the optimal", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 14, "year": "2002"}}
{"text": " originally derived by Friedman. It sequentially generates base models from a weighted version of the training data and searches the optimal combination of trees. At each step, a new base model is incorporated to correct the mistakes made by previous base models. Therefore, the gradient boosting method has the potential to provide a more accurate classifier. Moreover, GBDT derives feature contributing information from the fitted regression trees, which intrinsically perform feature selection by choosing appropriate split points, and it is able to handle different types of predictor variables with fit complex nonlinear relationship.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 15, "year": "2002"}}
{"text": " choosing appropriate split points, and it is able to handle different types of predictor variables with fit complex nonlinear relationship. The method shows a great performance in classification accuracy and timeliness on EEG, online visual tracking, prediction of hospital transfer and mortality, as well as short-term subway ridership. There are limited studies on the application of tree-based ensemble methods in rail vehicle fault diagnosis, and GBDT gets into trouble when it comes to class imbalance dataset.In this paper, an integrated approach of ADASYN–GBDT is proposed to build a rapid and high-performance multi-class classifier for the online detection of bogie fault based on the real-", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 16, "year": "2002"}}
{"text": "SYN–GBDT is proposed to build a rapid and high-performance multi-class classifier for the online detection of bogie fault based on the real-running data, especially with the treatment of imbalanced dataset. In the proposed method, the improved ADASYN is used to deal with the class imbalance problem; and GBDT works for achieving high classification accuracy and reduced time consumption. More importantly, the real-running data obtained from a Chinese subway company is used in the validation. A plain probe into the real-running data is also made to give a preliminary complex vibration characteristic of the bogie, in this paper.The rest of this paper is organized as follows.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 17, "year": "2002"}}
{"text": "also made to give a preliminary complex vibration characteristic of the bogie, in this paper.The rest of this paper is organized as follows. Section ‘‘Methodology’’ provides the proposed approach of bogie fault diagnosis. In section ‘‘Background and data analysis’’, description of bogie system composition, and common failure mode, and signal acquisition system are introduced. The comparison between the proposed integrated approach of ADASYN–GBDT and three commonly used classifiers (K-nearest neighbor, KNN; SVM; and Gaussian naı¨ve Bayes, GaussianNB) in bogie fault detection was done in section ‘‘Experiments’’.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 18, "year": "2002"}}
{"text": "ssifiers (K-nearest neighbor, KNN; SVM; and Gaussian naı¨ve Bayes, GaussianNB) in bogie fault detection was done in section ‘‘Experiments’’. The final section concludes the whole work.## MethodologyA multi-class classifier is proposed in this section. The proposed synthetic approach integrates the improved ADASYN and GBDT for more timely and precise diagnostic performance of a bogie fault, with consideration of the class imbalance dataset. GBDT works pretty well with respect to efficiency and accuracy as a classifier with the balanced dataset of high-dimension features.GBDT got good results in online visual tracking and short-term subway ridership, etc.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 19, "year": "2002"}}
{"text": "r with the balanced dataset of high-dimension features.GBDT got good results in online visual tracking and short-term subway ridership, etc. in both accuracy and operating implicity. By combining weak classification models, typically decision tree, with ‘poor’ performance, it usually produces high classification accuracy, and in contrast to other machine learning methods that have been treated as black-boxes, gradient boosting method provides interpretable results, while requiring little data preprocessing, and is able to handle different types of predictor variables with fit complex nonlinear relationship. It works pretty well in prediction and system identification with balance data.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 20, "year": "2002"}}
{"text": "predictor variables with fit complex nonlinear relationship. It works pretty well in prediction and system identification with balance data. However, there is little research shown that it can get a good result on imbalanced dataset of multi-class system. An improved ADASYN method is proposed to overcome such substance mentioned before.The improved ADASYN will make GBDT more suitable in our bogie multi-fault detection, where the characteristic of imbalance with multi-class is extremely prominent.## The improved adaptive synthetic sampling approachADASYN is mainly applied in medical and in binary systems. It increases the size of the minority class adaptively according to their density distri", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 21, "year": "2002"}}
{"text": "is mainly applied in medical and in binary systems. It increases the size of the minority class adaptively according to their density distributions, and makes the classifiers more sensitive to minority class, especially the difficult-to-learn samples. However, to our best knowledge, ADASYN has only been used in binary systems, which is the biggest limitation in many cases with multi-class in real world. The ignorance of outliers also makes it a little inferior.Some improvements have been made to generate new datasets to deal with multi-class data generation in this subsection.Step 1. Sort the classes according to sample number in each class, and find out the majority class.1.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 22, "year": "2002"}}
{"text": "ass data generation in this subsection.Step 1. Sort the classes according to sample number in each class, and find out the majority class.1. Calculate the ratio of class imbalance of second largest class, that iswhere rN1 2 (0, 1]. The classes that need to be resampled are arranged in order of their sample size to reduce the possibility of generating more samples on the decision boundary.2. If rN1 > rth, there is no need to generate new sample for SCN1; If rN1  0.5\nMulti-class ADASYN\nGBDT\nTrained ADASYN-GBDT Model\nResult\n**----- End of picture text -----**frequently where metal on the surface exfoliates or flakily lifts (shown in Figure 3).", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 23, "year": "2002"}}
{"text": "-GBDT Model\nResult\n**----- End of picture text -----**frequently where metal on the surface exfoliates or flakily lifts (shown in Figure 3). Friction heat makes the local tissue on the wheel tread to change and then the tread falls off when wheels slide on the rail. The other reason is the poor quality of wheel materials. Fatigue failure occurs after the wheel tread was extruded by the rail continuously. The shaft coupling is used to pass motor torque to the gear box, so as to drive the wheels. Shaft coupling misalignment (shown in Figure 4) may happen as results of shaft vibration and beat, bearing abrasion, bad stress, variable load, etc.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 24, "year": "2002"}}
{"text": "upling misalignment (shown in Figure 4) may happen as results of shaft vibration and beat, bearing abrasion, bad stress, variable load, etc. during train operation.## Signal acquisitionWe present a simplified structure of the signal acquisition network on the railway vehicle (shown in Figure 5). A brief introduction of the system is given as below.1. Vibration and temperature compound sensor is the general purpose accelerometer with internal2. Access point transfers data from the sensors to fusion point. Signal isolation processing, analogto-digital conversion, and digital signal filtering would be conducted by a signal conditioner in access point.3.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 25, "year": "2002"}}
{"text": "solation processing, analogto-digital conversion, and digital signal filtering would be conducted by a signal conditioner in access point.3. Fusion point and network point are used to do data concentration, data transmission and priority assignment (because this system is not only for running part. It works for real-time monitoring and per-warning of the whole vehicle), dynamic network organizing and so on.4. Service host receives data from the network point, and divides them into packets, then does data direction controlling and storage based on different subsystems of the railway vehicle. Actually, service host can also conduct safety assessment, fault diagnosis and per-warning, and suppor", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 26, "year": "2002"}}
{"text": "nt subsystems of the railway vehicle. Actually, service host can also conduct safety assessment, fault diagnosis and per-warning, and support terminal display. Our study is to find a more efficient method for this part.More details of this system are beyond our competence, and cannot be provided in this paper.## Data preparation and analysisThis section describes data preparation, summary of the datasets and the mechanism.Data preparation. Real-running vibration data of railway vehicles provided by a Chinese subway company are used in our study.Data were collected from a bullet-train carriage of type-A vehicle.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 27, "year": "2002"}}
{"text": "lway vehicles provided by a Chinese subway company are used in our study.Data were collected from a bullet-train carriage of type-A vehicle. The bullet-train carriage of the tested vehicle weighs about 38 tons, and its load is zero while testing. Each bullet-train contains two bogies, and each bogie has four wheels. Therefore, the load on each wheel is about 4.  tons.The rail vehicles were running on the track in a metro depot at a speed of 35  5 km=h while gathering the data. The schematic of the bogie and locations of vibration sensors are shown in Figure 6, and sample frequency is set to be 10 kHz. The permissible range of wheel diameter is 770–840 mm.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 28, "year": "2002"}}
{"text": "of vibration sensors are shown in Figure 6, and sample frequency is set to be 10 kHz. The permissible range of wheel diameter is 770–840 mm. We chose the half wear (also the mean value) wheel diameter to compute the rotate speed, which is about 3.  r/min/s.The dataset consists of four types of bogie conditions, operation with no trouble (Normal), wheel outof-roundness or flat (Fault 1), shaft misalignment (Fault 2), wheel run out (Fault 3). We got 2569– 2002 samples of operation with no trouble, 96 samples of wheel out-of-roundness or flat, and 96 samples of shaft misalignment, 375 samples of wheel run out. Each sample contains 32,768 points. The number of samples is not governed by us.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 29, "year": "2002"}}
{"text": "amples of shaft misalignment, 375 samples of wheel run out. Each sample contains 32,768 points. The number of samples is not governed by us. In most cases, rail vehicles would be stopped even there is a suspected fault or a slight fault, due to the strict actual**----- Start of picture text -----**\n Network Point (NP)\nFusion Point (FP)\nAccess Point (AP)\nVibration- Temperature\nCompound Sensor\nRunning Part\nVibration- Vibration-\nTemperature Temperature\nSignal Compound Sensor Compound Sensor\nAcquisition\nand\nPretreatment\nAccess Point (AP) Access Point (AP)\nFusion Point (FP) Fusion Point (FP)\nSignal\nProcess Network Point (NP)\nand\nControl Ethernet\nEthernet\nService Host", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 30, "year": "2002"}}
{"text": "oint (AP) Access Point (AP)\nFusion Point (FP) Fusion Point (FP)\nSignal\nProcess Network Point (NP)\nand\nControl Ethernet\nEthernet\nService Host\n**----- End of picture text -----**application requirements. It is a common situation that the fault diagnosis of rail vehicle is desperately short of useful samples in different failure modes, especially in various fault degrees.Data analysis. Time-domain waveform and their details under four conditions are shown in Figure 7. There are obvious periodic feature in bogie vibration data from its time-domain waveform. Amplitude of vibration in abnormal conditions was significantly larger than that in normal ones (shown as red rectangles in Figure 7).", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 31, "year": "2002"}}
{"text": "form. Amplitude of vibration in abnormal conditions was significantly larger than that in normal ones (shown as red rectangles in Figure 7). Vibration shows slight difference from the operation with no trouble to wheel run out condition. Signal possesses a clear sinusoidal property with random noise under condition of operation with no trouble, and shock characteristics in abnormal situations.Based on the above analysis and the real situation, the difficulties of online fault diagnosis of railway vehicle can be summarized as follows1. The velocity is hard to stay stable while testing, due to the route protection, switch protection, vehicle and its over-speed protection, as well as the driver", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 32, "year": "2002"}}
{"text": "d to stay stable while testing, due to the route protection, switch protection, vehicle and its over-speed protection, as well as the driver’s behavior. The running process increased the non-stationary level of the dynamic status signals and features.2. The data were collected on the same type vehicle, but not the same one. In addition, to get different fault type dataset, we detected vehicles in a long period. The data were easily interfered by the changeable environment. The characteristic of multi-formity and complexity affects method’s forecast accuracy and suitability of application.3. As faults occur occasionally, fault data are much smaller in size than those data in normal condition.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 33, "year": "2002"}}
{"text": "acy and suitability of application.3. As faults occur occasionally, fault data are much smaller in size than those data in normal condition. The typical imbalance characteristic makes misclassification more prone.4. Determination of vehicle failure and seizing the alarm substance in a very short period of time under such circumstances are also required for the real-time safety operation. Feature dimension should be reduced to get a high accuracy and reduced time consumption in classification. However, dimension reduction algorithm itself costs time.The complex relations between features, non-stationary of the signal, the class imbalance problem, together with the high accuracy and efficiency", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 34, "year": "2002"}}
{"text": "omplex relations between features, non-stationary of the signal, the class imbalance problem, together with the high accuracy and efficiency requirement make online bogie multi-fault detection verydifficult. Experiments are conducted in the next section to show how efficient the integrated model is.## ExperimentsTo test the effectiveness and robustness of the proposed ADASYN–GBDT method, this section comprehensively evaluates the performance of KNN, SVM, GaussianNB methods under different proportions of the test dataset.KNN is commonly used as a classifier method because of its simplicity and computational efficiency.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 35, "year": "2002"}}
{"text": "ifferent proportions of the test dataset.KNN is commonly used as a classifier method because of its simplicity and computational efficiency. It is also a lazy algorithm that does not use the training data points to do any generalization. In other words, it keeps all the training data during the testing phase, which has been widely applied in many areas.SVM is one of the best working classifiers, due to its excellent generalization ability. It reduces the claim on data scale and distribution by structural description of data distribution with margin concept. SVM showed state-of-the-art performance in realworld applications such as text categorization and bogie fault detection.Naı¨ve Bayes is", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 36, "year": "2002"}}
{"text": "pt. SVM showed state-of-the-art performance in realworld applications such as text categorization and bogie fault detection.Naı¨ve Bayes is totally different from other classifiers. Compared to most of the other classification methods – like decision tree, KNN, logistic, SVM, etc., which are all discriminating methods that learn the relationship between feature X and output Y directly, or the decision function Y ¼ f(X), or the conditional distribution P(YjX) – Naı¨ve Bayes is a generated method. It tries to find out the joint distribution P(X, Y) of feature X and output Y, then gets the result of P(YjX) ¼ P(X, Y)/P(X).", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 37, "year": "2002"}}
{"text": "erated method. It tries to find out the joint distribution P(X, Y) of feature X and output Y, then gets the result of P(YjX) ¼ P(X, Y)/P(X). Naı¨ve Bayes is intuitive, and not sensitive to missing data, with small computation volume. It works pretty well with respect to accuracy, precision, and specificity in the instructors’ performance evaluation.## Comparison and discussionAnalyses were performed with the Python system (version 3.5) and the scikit-learn (version 0.17.1) for statistical computing on a desktop computer with Intel(R) Core(TM) i3-3240 CPU @ 3.  GHz and 8.  GB RAM.Parameters in each classifier are set as below.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 38, "year": "2002"}}
{"text": " computing on a desktop computer with Intel(R) Core(TM) i3-3240 CPU @ 3.  GHz and 8.  GB RAM.Parameters in each classifier are set as below. As with the KNN method, we set the number of neighbors used to be 10, and all points in each neighborhood are weighted equally. Euclidean distance is used as the decision function of KNN. Support vector machine is a supervised learning model with associated learning algorithms that analyze data used for classification and regression analysis. It is widely used in railway vehicle fault diagnosis. In this paper, RBF kernel function and the shrinking heuristic are used, and penalty parameter C of the error term is set to be 1.0.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 39, "year": "2002"}}
{"text": "gnosis. In this paper, RBF kernel function and the shrinking heuristic are used, and penalty parameter C of the error term is set to be 1.0. Tolerance for stopping criterion is 1e  3. All classes are supposed to have weight one. Parameters in GaussianNB method are default, where the prior probabilities of each class are adjusted according to the input data, and the weight applied to individual samples is 1. As to GBDT method, the number of boosting stages to perform, subsample values is 0.8, the deviance loss function is chosen as the deviance for classification with probabilistic outputs, and learning rate is 0.1, while the number of boosting stages to perform and the maximum depth of the i", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 40, "year": "2002"}}
{"text": "fication with probabilistic outputs, and learning rate is 0.1, while the number of boosting stages to perform and the maximum depth of the individual regression estimators are 100 and 4, respectively. The Friedman mean squared error with improvement is used here. Other parameters are set as default.1. Performance comparison is taken between ADASYN–GBDT and KNN, SVM, GaussianNB. We are trying to present the great performance of ADASYN–GBDT in multi-class classification and the superiority on imbalanced dataset. The proportion of the test dataset is set to be 0.4.The grid color represents the percentage of the sample number that is classified into the corresponding classes, as shown in the str", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 41, "year": "2002"}}
{"text": " be 0.4.The grid color represents the percentage of the sample number that is classified into the corresponding classes, as shown in the stripe on the right of each confusion matrix . For example, in the firstPrediction negative| |True condition\nCondition positive\nCondition negative|True positive (TP)\nFalse negative (FN)\nFalse positive (FP)\nTrue negative (TN)|column of Figure 8(a), 0.9200 is diagnostic accuracy of normal class, and 0.0200, 0.0050, and 0.0550 is the percentages of normal samples which are misclassified into Fault 1, Fault 2, and Fault 3 class, respectively. Values that lie along the diagonal from top left to bottom right of each matrix are the precisions of the given four bog", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 42, "year": "2002"}}
{"text": "lass, respectively. Values that lie along the diagonal from top left to bottom right of each matrix are the precisions of the given four bogie conditions.From Figure 8(a) and (b), different methods are sensitive to different failure modes, KNN and SVM are more likely affected by the imbalanced dataset, especially SVM, and samples in minority classes are more likely to be misclassified to the majority class. KNN works by accounting the number of samples that belong to certain class of the K-nearest neighbor among the objective. It is obvious that the likelihood of target sample classified into the majority class is greater than that into the minority ones.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 43, "year": "2002"}}
{"text": "bjective. It is obvious that the likelihood of target sample classified into the majority class is greater than that into the minority ones. Furthermore, SVM is overfitting in our case due tothe disparity of dataset, as the total penalty coefficient to samples in majority class is much greater than that to minority classes.GaussianNB method gets a high accuracy of 94.59% only in Fault 1 class as shown in Figure 8(c). However, results of other three categories are far from acceptable, in particular with regard to the bogie normal state. Samples in normal state are more likely misclassified into the Fault 2 and Fault 3 classes with the high errors possibilities of 0.2375 and 0.5088.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 44, "year": "2002"}}
{"text": " in normal state are more likely misclassified into the Fault 2 and Fault 3 classes with the high errors possibilities of 0.2375 and 0.5088. And about 25.97% of samples in Fault 3 condition were misclassified as Fault 1. That may be caused by the assumption that features are independent between each other, as well as the feature distribution of normal, Fault 2 and Fault 3 samples in each dimension is not subjected to Gaussian distribution which is the basic requirement of GaussianNB algorithm.As illustrated in Figure 8(a) to (c), KNN, SVM and GaussianNB methods have difficulties in identifying the bogie condition and will cause high false alarm rate and missed alarm rate, which would result", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 45, "year": "2002"}}
{"text": "methods have difficulties in identifying the bogie condition and will cause high false alarm rate and missed alarm rate, which would result in unnecessary inspection and cost in time and money.The best result is obtained by our proposed method, ADASYN–GBDT. The integrated syntheticKNN: K-nearest neighbor; SVM: support vector machine; GaussianNB: Gaussian naı¨ve Bayes; ADASYN–GBDT: adaptive synthetic sampling approach–gradient boosting decision tree.ADASYN–GBDT method took advantages of both ADASYN and GBDT method. ADASYN is set to solve the class imbalance problem in practical railway operation. It adaptively generates new samples of minority classes.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 46, "year": "2002"}}
{"text": " ADASYN is set to solve the class imbalance problem in practical railway operation. It adaptively generates new samples of minority classes. While GBDT derives feature contributing information from the fitted regression trees which intrinsically perform feature selection by choosing appropriate split points, it is able to handle different types of predictor variables with fit complex nonlinear relationship. In addition, GBDT is an ensemble method. By combining weak classification models, typically decision tree, with ‘poor’ performance, it usually produces high classification accuracy. In contrast to other machine learning methods that have been treated as black-boxes, gradient boosting meth", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 47, "year": "2002"}}
{"text": "es high classification accuracy. In contrast to other machine learning methods that have been treated as black-boxes, gradient boosting method provides interpretable results, while requiring little data preprocessing, and is able to handle different types of predictor variables with fit complex nonlinear relationship. It works pretty well in bogie multi-fault detection of railway vehicle in both accuracy and operating implicity.We ran 100 trials and calculated the average execute time of each method as illustrated in Table 2. Without consideration of diagnosis accuracy, KNN and Gaussian are the fastest two methods, and they have the same order of magnitude in consuming time.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 48, "year": "2002"}}
{"text": "sideration of diagnosis accuracy, KNN and Gaussian are the fastest two methods, and they have the same order of magnitude in consuming time. However, much more effort should be taken to improve the precision, which is the top-priority in bogie fault diagnosis. Although ADASYN–GBDT is not the fastest method, it is faster and more accurate than SVM. Consuming time in detection procedure averages 0.0027 s. As the sample frequency is 10 k/s and a sample contains 32,768 data points, it takes about 3.  s to obtain a sample and then input to our algorithm, which means our proposed method satisfies the requirements of real-time performance and accuracy for online fault detection of bogies.2.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 49, "year": "2002"}}
{"text": "hm, which means our proposed method satisfies the requirements of real-time performance and accuracy for online fault detection of bogies.2. Performance comparison is taken under different proportions of the test dataset to show the generalization ability of our ADASYN–GBDT method. Proportion of the test dataset is set to be 0.4, 0.6, 0.8, 0.  in this regard.The overall performance of the proposed ADASYN–GBDT method in fault detection is pretty good; more than 94% of faults are detected successfully when the test data size ¼ 0.  (shown in Figure 9(a)). Even in the case of test data size ¼ 0.9, the lowest fault detection rate is still 87.81% (detection of Fault 2, shown in Figure 9(d)).", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 50, "year": "2002"}}
{"text": "a)). Even in the case of test data size ¼ 0.9, the lowest fault detection rate is still 87.81% (detection of Fault 2, shown in Figure 9(d)). False positive rates of normal state are 0.0705, 0.0863, 0.0841 and 0.0980 in the four cases, respectively, which is indeed acceptable. The robustness of ADASYN–GBDT method makes it more suitable for multi-class fault diagnosis, especially when the training data size is relatively small.Samples of normal state are more likely to be misclassified to Fault 3, as there is a tolerance margin of the natural attrition for wheel before it is decommissioned. Fault 1 is easier to be identified than the other three conditions, because signal has more pronounced r", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 51, "year": "2002"}}
{"text": " wheel before it is decommissioned. Fault 1 is easier to be identified than the other three conditions, because signal has more pronounced response to the impact caused by wheel out-of-roundness or flat. Manifestation and amplitude of axle misalignment are similar to that of wheel out-of-roundness or flat in time-domain signal, and most features used in this paper are in time domain and reflect the signal energy, so it is no surprise that the higher ratio of Fault 2 was misclassified into Fault 1 than into normal and Fault 3 conditions.With the decrease of training data size, a slight drop of diagnosis accuracy for all conditions shows up.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 52, "year": "2002"}}
{"text": "into normal and Fault 3 conditions.With the decrease of training data size, a slight drop of diagnosis accuracy for all conditions shows up. The performance of our proposed method is still subjected to sample size which is a common failing of machine learning algorithms.In addition, the accuracy of three faults’ detection is a little higher than that of samples in normal state.It indicates that the integrated synthetic ADASYN– GBDT method not only overcomes the class imbalance problem in the original datasets by artificially generating data samples in minority classes, but also pays more attention to fault detection by shifting its decision boundary to focus on those hard-to-learn examples w", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 53, "year": "2002"}}
{"text": "nority classes, but also pays more attention to fault detection by shifting its decision boundary to focus on those hard-to-learn examples which are the fault samples in our cases. That is really significant in our rail vehicle fault diagnosis to reduce operational risk and to avoid sudden failure.## ConclusionIn this study, an ADASYN–GBDT approach is investigated to detect bogie fault, with the consideration of imbalanced data of multi-classes which is very common in fault diagnosis of railway vehicle. The proposed ADASYN–GBDT model produced great results wherein the fault detection rate is at least 0.  with false positive rates of 0.0583 (when the proportion of the test dataset is 0.4); th", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 54, "year": "2002"}}
{"text": "ts wherein the fault detection rate is at least 0.  with false positive rates of 0.0583 (when the proportion of the test dataset is 0.4); the total executed time is 2.4231 s, detection time is 0.0027 s – on average – which is much shorter than the time of a sample, indicating that the ADASYN–GBDT model can be successfully used for real-time bogie fault detection.The GBDT model can automatically select relevant variables, fit accurate models, and identify and model parameter interactions. More importantly, different from other machine learning algorithms which are working as a ‘black-box’, this model provides clear internal functioning mechanism, which is critical for engineering control.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 55, "year": "2002"}}
{"text": "hms which are working as a ‘black-box’, this model provides clear internal functioning mechanism, which is critical for engineering control. In addition, a comparison between KNN, SVM, GaussianNB and the proposed model indicates that the ADASYN–GBDT model is more suitable for multi-class imbalanced data classification with regard to its effectiveness and robustness in fault detection.Our future work will explore the signal characteristics to extract more effective features. The classifier on a small sample size is also a research priority, because such a problem is more prominent in diagnosing a bogie fault in a practical situation.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 56, "year": "2002"}}
