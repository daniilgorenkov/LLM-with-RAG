{"text": "introduction of the system is given as below.1. Vibration and temperature compound sensor is the general purpose accelerometer with internal2. Access point transfers data from the sensors to fusion point. Signal isolation processing, analogto-digital conversion, and digital signal filtering would be conducted by a signal conditioner in access point.3. Fusion point and network point are used to do data concentration, data transmission and priority assignment (because this system is not only for running part. It works for real-time monitoring and per-warning of the whole vehicle), dynamic network organizing and so on.4.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 0, "year": "2002"}}
{"text": " not only for running part. It works for real-time monitoring and per-warning of the whole vehicle), dynamic network organizing and so on.4. Service host receives data from the network point, and divides them into packets, then does data direction controlling and storage based on different subsystems of the railway vehicle. Actually, service host can also conduct safety assessment, fault diagnosis and per-warning, and support terminal display. Our study is to find a more efficient method for this part.More details of this system are beyond our competence, and cannot be provided in this paper.## Data preparation and analysisThis section describes data preparation, summary of the datasets and", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 1, "year": "2002"}}
{"text": ", and cannot be provided in this paper.## Data preparation and analysisThis section describes data preparation, summary of the datasets and the mechanism.Data preparation. Real-running vibration data of railway vehicles provided by a Chinese subway company are used in our study.Data were collected from a bullet-train carriage of type-A vehicle. The bullet-train carriage of the tested vehicle weighs about 38 tons, and its load is zero while testing. Each bullet-train contains two bogies, and each bogie has four wheels. Therefore, the load on each wheel is about 4.  tons.The rail vehicles were running on the track in a metro depot at a speed of 35  5 km=h while gathering the data.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 2, "year": "2002"}}
{"text": "each wheel is about 4.  tons.The rail vehicles were running on the track in a metro depot at a speed of 35  5 km=h while gathering the data. The schematic of the bogie and locations of vibration sensors are shown in Figure 6, and sample frequency is set to be 10 kHz. The permissible range of wheel diameter is 770–840 mm. We chose the half wear (also the mean value) wheel diameter to compute the rotate speed, which is about 3.  r/min/s.The dataset consists of four types of bogie conditions, operation with no trouble (Normal), wheel outof-roundness or flat (Fault 1), shaft misalignment (Fault 2), wheel run out (Fault 3).", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 3, "year": "2002"}}
{"text": "ditions, operation with no trouble (Normal), wheel outof-roundness or flat (Fault 1), shaft misalignment (Fault 2), wheel run out (Fault 3). We got 2569– 2002 samples of operation with no trouble, 96 samples of wheel out-of-roundness or flat, and 96 samples of shaft misalignment, 375 samples of wheel run out. Each sample contains 32,768 points. The number of samples is not governed by us. In most cases, rail vehicles would be stopped even there is a suspected fault or a slight fault, due to the strict actualNetwork Point (NP)<br>Fusion Point (FP)<br>Access Point (AP)<br>Vibration- Temperature<br>Compound Sensor<br>Running Part<br>Vibration- Vibration-<br>Temperature Temperature<br>Signal Com", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 4, "year": "2002"}}
{"text": "ss Point (AP)<br>Vibration- Temperature<br>Compound Sensor<br>Running Part<br>Vibration- Vibration-<br>Temperature Temperature<br>Signal Compound Sensor Compound Sensor<br>Acquisition<br>and<br>Pretreatment<br>Access Point (AP) Access Point (AP)<br>Fusion Point (FP) Fusion Point (FP)<br>Signal<br>Process Network Point (NP)<br>and<br>Control Ethernet<br>Ethernet<br>Service Host<br>**----- End of picture text -----**<br>application requirements. It is a common situation that the fault diagnosis of rail vehicle is desperately short of useful samples in different failure modes, especially in various fault degrees.Data analysis.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 5, "year": "2002"}}
{"text": "gnosis of rail vehicle is desperately short of useful samples in different failure modes, especially in various fault degrees.Data analysis. Time-domain waveform and their details under four conditions are shown in Figure 7. There are obvious periodic feature in bogie vibration data from its time-domain waveform. Amplitude of vibration in abnormal conditions was significantly larger than that in normal ones (shown as red rectangles in Figure 7). Vibration shows slight difference from the operation with no trouble to wheel run out condition. Signal possesses a clear sinusoidal property with random noise under condition of operation with no trouble, and shock characteristics in abnormal situat", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 6, "year": "2002"}}
{"text": "ses a clear sinusoidal property with random noise under condition of operation with no trouble, and shock characteristics in abnormal situations.Based on the above analysis and the real situation, the difficulties of online fault diagnosis of railway vehicle can be summarized as follows1. The velocity is hard to stay stable while testing, due to the route protection, switch protection, vehicle and its over-speed protection, as well as the driver’s behavior. The running process increased the non-stationary level of the dynamic status signals and features.2. The data were collected on the same type vehicle, but not the same one.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 7, "year": "2002"}}
{"text": "e non-stationary level of the dynamic status signals and features.2. The data were collected on the same type vehicle, but not the same one. In addition, to get different fault type dataset, we detected vehicles in a long period. The data were easily interfered by the changeable environment. The characteristic of multi-formity and complexity affects method’s forecast accuracy and suitability of application.3. As faults occur occasionally, fault data are much smaller in size than those data in normal condition. The typical imbalance characteristic makes misclassification more prone.4. Determination of vehicle failure and seizing the alarm substance in a very short period of time under such ci", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 8, "year": "2002"}}
{"text": "isclassification more prone.4. Determination of vehicle failure and seizing the alarm substance in a very short period of time under such circumstances are also required for the real-time safety operation. Feature dimension should be reduced to get a high accuracy and reduced time consumption in classification. However, dimension reduction algorithm itself costs time.The complex relations between features, non-stationary of the signal, the class imbalance problem, together with the high accuracy and efficiency requirement make online bogie multi-fault detection verydifficult. Experiments are conducted in the next section to show how efficient the integrated model is.## ExperimentsTo test the", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 9, "year": "2002"}}
{"text": "tection verydifficult. Experiments are conducted in the next section to show how efficient the integrated model is.## ExperimentsTo test the effectiveness and robustness of the proposed ADASYN–GBDT method, this section comprehensively evaluates the performance of KNN, SVM, GaussianNB methods under different proportions of the test dataset.KNN is commonly used as a classifier method because of its simplicity and computational efficiency. It is also a lazy algorithm that does not use the training data points to do any generalization. In other words, it keeps all the training data during the testing phase, which has been widely applied in many areas.SVM is one of the best working classifiers, d", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 10, "year": "2002"}}
{"text": "ps all the training data during the testing phase, which has been widely applied in many areas.SVM is one of the best working classifiers, due to its excellent generalization ability. It reduces the claim on data scale and distribution by structural description of data distribution with margin concept. SVM showed state-of-the-art performance in realworld applications such as text categorization and bogie fault detection.Naı¨ve Bayes is totally different from other classifiers. Compared to most of the other classification methods – like decision tree, KNN, logistic, SVM, etc., which are all discriminating methods that learn the relationship between feature X and output Y directly, or the deci", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 11, "year": "2002"}}
{"text": ", logistic, SVM, etc., which are all discriminating methods that learn the relationship between feature X and output Y directly, or the decision function Y ¼ f(X), or the conditional distribution P(YjX) – Naı¨ve Bayes is a generated method. It tries to find out the joint distribution P(X, Y) of feature X and output Y, then gets the result of P(YjX) ¼ P(X, Y)/P(X). Naı¨ve Bayes is intuitive, and not sensitive to missing data, with small computation volume. It works pretty well with respect to accuracy, precision, and specificity in the instructors’ performance evaluation.## Comparison and discussionAnalyses were performed with the Python system (version 3.5) and the scikit-learn (version 0.17", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 12, "year": "2002"}}
{"text": "mance evaluation.## Comparison and discussionAnalyses were performed with the Python system (version 3.5) and the scikit-learn (version 0.17.1) for statistical computing on a desktop computer with Intel(R) Core(TM) i3-3240 CPU @ 3.  GHz and 8.  GB RAM.Parameters in each classifier are set as below. As with the KNN method, we set the number of neighbors used to be 10, and all points in each neighborhood are weighted equally. Euclidean distance is used as the decision function of KNN. Support vector machine is a supervised learning model with associated learning algorithms that analyze data used for classification and regression analysis. It is widely used in railway vehicle fault diagnosis.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 13, "year": "2002"}}
{"text": "learning algorithms that analyze data used for classification and regression analysis. It is widely used in railway vehicle fault diagnosis. In this paper, RBF kernel function and the shrinking heuristic are used, and penalty parameter C of the error term is set to be 1.0. Tolerance for stopping criterion is 1e  3. All classes are supposed to have weight one. Parameters in GaussianNB method are default, where the prior probabilities of each class are adjusted according to the input data, and the weight applied to individual samples is 1. As to GBDT method, the number of boosting stages to perform, subsample values is 0.8, the deviance loss function is chosen as the deviance for classificatio", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 14, "year": "2002"}}
{"text": "d, the number of boosting stages to perform, subsample values is 0.8, the deviance loss function is chosen as the deviance for classification with probabilistic outputs, and learning rate is 0.1, while the number of boosting stages to perform and the maximum depth of the individual regression estimators are 100 and 4, respectively. The Friedman mean squared error with improvement is used here. Other parameters are set as default.1. Performance comparison is taken between ADASYN–GBDT and KNN, SVM, GaussianNB. We are trying to present the great performance of ADASYN–GBDT in multi-class classification and the superiority on imbalanced dataset.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 15, "year": "2002"}}
{"text": "anNB. We are trying to present the great performance of ADASYN–GBDT in multi-class classification and the superiority on imbalanced dataset. The proportion of the test dataset is set to be 0.4.The grid color represents the percentage of the sample number that is classified into the corresponding classes, as shown in the stripe on the right of each confusion matrix . For example, in the firstcolumn of Figure 8(a), 0.9200 is diagnostic accuracy of normal class, and 0.0200, 0.0050, and 0.0550 is the percentages of normal samples which are misclassified into Fault 1, Fault 2, and Fault 3 class, respectively. Values that lie along the diagonal from top left to bottom right of each matrix are the", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 16, "year": "2002"}}
{"text": " Fault 1, Fault 2, and Fault 3 class, respectively. Values that lie along the diagonal from top left to bottom right of each matrix are the precisions of the given four bogie conditions.From Figure 8(a) and (b), different methods are sensitive to different failure modes, KNN and SVM are more likely affected by the imbalanced dataset, especially SVM, and samples in minority classes are more likely to be misclassified to the majority class. KNN works by accounting the number of samples that belong to certain class of the K-nearest neighbor among the objective. It is obvious that the likelihood of target sample classified into the majority class is greater than that into the minority ones.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 17, "year": "2002"}}
{"text": "bjective. It is obvious that the likelihood of target sample classified into the majority class is greater than that into the minority ones. Furthermore, SVM is overfitting in our case due tothe disparity of dataset, as the total penalty coefficient to samples in majority class is much greater than that to minority classes.GaussianNB method gets a high accuracy of 94.59% only in Fault 1 class as shown in Figure 8(c). However, results of other three categories are far from acceptable, in particular with regard to the bogie normal state. Samples in normal state are more likely misclassified into the Fault 2 and Fault 3 classes with the high errors possibilities of 0.2375 and 0.5088.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 18, "year": "2002"}}
{"text": " in normal state are more likely misclassified into the Fault 2 and Fault 3 classes with the high errors possibilities of 0.2375 and 0.5088. And about 25.97% of samples in Fault 3 condition were misclassified as Fault 1. That may be caused by the assumption that features are independent between each other, as well as the feature distribution of normal, Fault 2 and Fault 3 samples in each dimension is not subjected to Gaussian distribution which is the basic requirement of GaussianNB algorithm.As illustrated in Figure 8(a) to (c), KNN, SVM and GaussianNB methods have difficulties in identifying the bogie condition and will cause high false alarm rate and missed alarm rate, which would result", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 19, "year": "2002"}}
{"text": "methods have difficulties in identifying the bogie condition and will cause high false alarm rate and missed alarm rate, which would result in unnecessary inspection and cost in time and money.The best result is obtained by our proposed method, ADASYN–GBDT. The integrated syntheticKNN: K-nearest neighbor; SVM: support vector machine; GaussianNB: Gaussian naı¨ve Bayes; ADASYN–GBDT: adaptive synthetic sampling approach–gradient boosting decision tree.ADASYN–GBDT method took advantages of both ADASYN and GBDT method. ADASYN is set to solve the class imbalance problem in practical railway operation. It adaptively generates new samples of minority classes.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 20, "year": "2002"}}
{"text": " ADASYN is set to solve the class imbalance problem in practical railway operation. It adaptively generates new samples of minority classes. While GBDT derives feature contributing information from the fitted regression trees which intrinsically perform feature selection by choosing appropriate split points, it is able to handle different types of predictor variables with fit complex nonlinear relationship. In addition, GBDT is an ensemble method. By combining weak classification models, typically decision tree, with ‘poor’ performance, it usually produces high classification accuracy. In contrast to other machine learning methods that have been treated as black-boxes, gradient boosting meth", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 21, "year": "2002"}}
{"text": "es high classification accuracy. In contrast to other machine learning methods that have been treated as black-boxes, gradient boosting method provides interpretable results, while requiring little data preprocessing, and is able to handle different types of predictor variables with fit complex nonlinear relationship. It works pretty well in bogie multi-fault detection of railway vehicle in both accuracy and operating implicity.We ran 100 trials and calculated the average execute time of each method as illustrated in Table 2. Without consideration of diagnosis accuracy, KNN and Gaussian are the fastest two methods, and they have the same order of magnitude in consuming time.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 22, "year": "2002"}}
{"text": "sideration of diagnosis accuracy, KNN and Gaussian are the fastest two methods, and they have the same order of magnitude in consuming time. However, much more effort should be taken to improve the precision, which is the top-priority in bogie fault diagnosis. Although ADASYN–GBDT is not the fastest method, it is faster and more accurate than SVM. Consuming time in detection procedure averages 0.0027 s. As the sample frequency is 10 k/s and a sample contains 32,768 data points, it takes about 3.  s to obtain a sample and then input to our algorithm, which means our proposed method satisfies the requirements of real-time performance and accuracy for online fault detection of bogies.2.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 23, "year": "2002"}}
{"text": "hm, which means our proposed method satisfies the requirements of real-time performance and accuracy for online fault detection of bogies.2. Performance comparison is taken under different proportions of the test dataset to show the generalization ability of our ADASYN–GBDT method. Proportion of the test dataset is set to be 0.4, 0.6, 0.8, 0.  in this regard.The overall performance of the proposed ADASYN–GBDT method in fault detection is pretty good; more than 94% of faults are detected successfully when the test data size ¼ 0.  (shown in Figure 9(a)). Even in the case of test data size ¼ 0.9, the lowest fault detection rate is still 87.81% (detection of Fault 2, shown in Figure 9(d)).", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 24, "year": "2002"}}
{"text": "a)). Even in the case of test data size ¼ 0.9, the lowest fault detection rate is still 87.81% (detection of Fault 2, shown in Figure 9(d)). False positive rates of normal state are 0.0705, 0.0863, 0.0841 and 0.0980 in the four cases, respectively, which is indeed acceptable. The robustness of ADASYN–GBDT method makes it more suitable for multi-class fault diagnosis, especially when the training data size is relatively small.Samples of normal state are more likely to be misclassified to Fault 3, as there is a tolerance margin of the natural attrition for wheel before it is decommissioned. Fault 1 is easier to be identified than the other three conditions, because signal has more pronounced r", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 25, "year": "2002"}}
{"text": " wheel before it is decommissioned. Fault 1 is easier to be identified than the other three conditions, because signal has more pronounced response to the impact caused by wheel out-of-roundness or flat. Manifestation and amplitude of axle misalignment are similar to that of wheel out-of-roundness or flat in time-domain signal, and most features used in this paper are in time domain and reflect the signal energy, so it is no surprise that the higher ratio of Fault 2 was misclassified into Fault 1 than into normal and Fault 3 conditions.With the decrease of training data size, a slight drop of diagnosis accuracy for all conditions shows up.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 26, "year": "2002"}}
{"text": "into normal and Fault 3 conditions.With the decrease of training data size, a slight drop of diagnosis accuracy for all conditions shows up. The performance of our proposed method is still subjected to sample size which is a common failing of machine learning algorithms.In addition, the accuracy of three faults’ detection is a little higher than that of samples in normal state.It indicates that the integrated synthetic ADASYN– GBDT method not only overcomes the class imbalance problem in the original datasets by artificially generating data samples in minority classes, but also pays more attention to fault detection by shifting its decision boundary to focus on those hard-to-learn examples w", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 27, "year": "2002"}}
{"text": "nority classes, but also pays more attention to fault detection by shifting its decision boundary to focus on those hard-to-learn examples which are the fault samples in our cases. That is really significant in our rail vehicle fault diagnosis to reduce operational risk and to avoid sudden failure.## ConclusionIn this study, an ADASYN–GBDT approach is investigated to detect bogie fault, with the consideration of imbalanced data of multi-classes which is very common in fault diagnosis of railway vehicle. The proposed ADASYN–GBDT model produced great results wherein the fault detection rate is at least 0.  with false positive rates of 0.0583 (when the proportion of the test dataset is 0.4); th", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 28, "year": "2002"}}
{"text": "ts wherein the fault detection rate is at least 0.  with false positive rates of 0.0583 (when the proportion of the test dataset is 0.4); the total executed time is 2.4231 s, detection time is 0.0027 s – on average – which is much shorter than the time of a sample, indicating that the ADASYN–GBDT model can be successfully used for real-time bogie fault detection.The GBDT model can automatically select relevant variables, fit accurate models, and identify and model parameter interactions. More importantly, different from other machine learning algorithms which are working as a ‘black-box’, this model provides clear internal functioning mechanism, which is critical for engineering control.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 29, "year": "2002"}}
{"text": "hms which are working as a ‘black-box’, this model provides clear internal functioning mechanism, which is critical for engineering control. In addition, a comparison between KNN, SVM, GaussianNB and the proposed model indicates that the ADASYN–GBDT model is more suitable for multi-class imbalanced data classification with regard to its effectiveness and robustness in fault detection.Our future work will explore the signal characteristics to extract more effective features. The classifier on a small sample size is also a research priority, because such a problem is more prominent in diagnosing a bogie fault in a practical situation.", "metadata": {"doc_id": "Integrating synthetic minority", "section": "ROOT", "level": 0, "chunk_id": 30, "year": "2002"}}
