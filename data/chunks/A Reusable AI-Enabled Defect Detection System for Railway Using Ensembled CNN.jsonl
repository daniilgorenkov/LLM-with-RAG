{"text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 0, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "stantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) fr", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 1, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "ions\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect det", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 2, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "g the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our propos", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 3, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 4, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "nd efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 5, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": ", Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 6, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the imag", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 7, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "racy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For exampl", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 8, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": ". , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly u", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 9, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "ding camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficienc", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 10, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "ng and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accurac", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 11, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robu", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 12, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 13, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "on is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new trainin", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 14, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convoluti", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 15, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or d", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 16, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "ch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, includin", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 17, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "umber of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 i", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 18, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. T", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 19, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 20, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN mo", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 21, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "ere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max poo", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 22, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "t the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 23, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-t", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 24, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "ve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epoc", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 25, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "r the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the hea", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 26, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "his requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that af", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 27, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. T", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 28, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "odels also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 29, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 30, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 31, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "ation. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefe", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 32, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "es. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 33, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "dictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway de", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 34, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
{"text": "uracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "metadata": {"doc_id": "A Reusable AI-Enabled Defect Detection System for Railway Using Ensembled CNN", "section": "A Reusable AI-Enabled Defect Detection System", "level": 2, "chunk_id": 35, "text": "# for Railway Using Ensembled CNN1*School of Electrical Engineering and Computer Science, University of10587, Abu Dhabi, UAE. National Research Council,, 1200\nMontreal Rd,Accurate Defect detection is crucial for ensuring the trustworthiness of intelli-gent\nrailway systems. Current approaches rely on single deep-learning models, like\nCNNs, which employ a large amount of data to capture underlying patterns.\npoor performance on unseen images. To address this, researchers have advocated transfer learning and fine-tuning the pre-trained models. However, using a\nand inconsistent performance if it is not suitable for a specific problem domain.\nTo overcome these challenges, we propose a reusable AI-enabled defect detection approach. By combining ensemble learning with transfer learning models\n(VGG-19, MobileNetV3, and ResNet-50), we improved the classification accuracy and achieved consistent performance at a certain phase of training. Our\nother state-of-the-art approaches. The consistency substantiates the reusability of the defect detection system for newly evolved defected rail parts. Therefore we### 1\nIntroductionThe issue of railway defect detection has become increasingly complex, as the defect domain in railways rapidly changes. For instance, some defects may closely\nresem-ble normal railway components, making it difficult to visually differentiate\nthem and emphasizing the need for reusable detection methods. Even with\nprogress in Com-puter Vision (CV) techniques, Railway Defect detection is\nchallenging due to multiple factors such as the complexity of railway infrastructure,\ndifferences in lighting and weather conditions, and the inclusion of noise in image\ndata. With the emergence of Artificial Intelligence technology, more advanced CV.In railway, there is a need to develop effective methods for managing defectNumerous studies have already been conducted for Railway defect detection, making use of various CV techniques [2–4]. However, there are some notable limitations\nincluding reliance on handcrafted features and difficulty handling complex images. With the recent development of AI models, integration of Deep Learning (DL) models into the\nDigital Twin (DT) framework has shown promising results in railway defect Detection .\nThe employment of DL has been increasing when it comes to auto-mated defect detection within railway infrastructure and .In addition, the use of Convolutionaldetect various types of railway defects with high accuracy. Neverthe-less, there are still gaps that need to be addressed in this field. The requirement for a large sample size forlead to lower accuracy . Transfer learning has been commonly used to address the period . Fine-tuning pre-trained CNN allow new models to utilize the knowledge\nextracted from large-scale datasets by transferingr the knowledge . However, in the context of railway defect detection, using single backbone network for transfer learningfor railway maintenance . In this research, we focus on detailing the AI\nInferencing engine of this framework for defect detection of rail freights. Our main1. We propose the integration of ensembled and fine-tuned models for reusable AI\nenabled railway defect detection. Although this approach has been applied in\nother domains, such as medical imaging analysis , its application to railway2. We designed an algorithm for ensembling fine-tuned CNN models that optimize3. We conducted a thorough complexity analysis of the proposed algorithm. ThisWe conducted three distinct experiments utilizing the dataset from the Canadian Pacific Railways (CPR) dataset, which includes 1000 defective and 20004. We found data augmentation technique improves the accuracy but still shows sig\nnificant overfitting issues for the CPR dataset. We identified that identical\ndefective and normal images exist in CPR data, which poses a challenge to5. We empirically evaluated the impact of transfer learning with VGG-19,MobileNetV3, and ResNet50 models on CPR dataset. This approach effectively\nreduces overfitting and ensures high accuracy. Among these models, ResNet\nachieves the highest accuracy, while MobileNet exhibits the least loss.6. We implemented and evaluated our proposed model, which achieves 99%predic-tion accuracy, reduces overfitting, and maintains stable performance after\na certain epoch. By comparing our results with existing work, we demonstrate that our model outperforms other state-of-the-art models in classifying defects.The remainder of the paper is organized as followings in Section 2, we outlined how DL has been used for digital twin defect detection in railways. Also, we summarized the data employed for this purpose.The related work is followed by Section 3, where we selecting transfer learning and ensembling as the underlying technology for rail-defect detection. In Section 5, we presented the data, experiment, and outcomes of the experiment with a description. Finally, we concluded the research by outlining the### 2\nRelated Workthe safe and efficient operation of trains. The traditional inspection method is laborintensive and time-consuming, hence the need for advanced techniques to\nautomate this process. CV-enabled technologies have been proposed as viable solutions for rail-way defect detection . In this section, we present related work onSupervised machine learning (SVM) algorithms have been applied to various components of the railway system. Authors in , used SVM for classifying tracks in\ngrinding condition and tracks with severe damage with an accuracy of over 95%.\nHow-ever, SVM can be particularly useful when the data is well-structured and the features are well-defined, as it can provide a simple and efficient way to separateDeep learning algorithms, such as CNN , has significantly improved the accuracy and efficiency of defect detection. CNNs are a class of deep artificial neural networks One- 1D CNN Fasteners in different degra- High detection accuracyFreight defect Image Classification Deep CNN Recall-80.48%, Precision78.20%, F1-score-79.32%Sequence data 1DCNN and long- Rail Surface Dataset-1: Recall 0.9314,\nclassification and short-term mem- Precision 0.8421, F1ory (LSTM) Measure 0.8845; Dataset-2:that rely on local linear operations followed by non-linear transformations, creating\ndifferent representations of the input data . They have been shown to extract low-level features such as object edges and high-level features such as objectBased on the Table 1, it is evident that CNN has been widely employed for railway defect detection, using various methods such as image classification, object detection,\nsemantic segmentation, and sequence data classification. The reason behind the popularity of using CNN for defect classification is- its ability to process and learn from large\namounts of complex data, such as images and sensor readings, and to detectunseen patterns (e.g., crack) and anomalies (e.g., faulty valves) that may be difficult\nto discern using traditional machine learning or rule-based methods .The authors in , used a Deep CNN model to detect normal rails, small\ndefects, and squats, achieving an accuracy of 92%. Similarly, the evaluation in ,\ndemon-strated high accuracy at 96.9% accuracy in detecting normal and defective squats. Authors in , used one-dimensional CNN to detect fasteners in different\ndegrada-tion conditions with high accuracy. The research in , used Deep CNN\nfor image classification of freight defects, achieving a recall of 80.48%, precision of\n78.20%, and F1-score of 79.32%. The study , applied object detection with\nYOLOv3 to detect defects in rails with a high accuracy of 97%. Another study in, used MobileNetv2 and YOLOv3 for object detection, achieving 87.4% accuracySome studies have also applied semantic segmentation-based object detection, which involves dividing an image into segments and assigning each segment a label, for defect\ndetection. For example, Liang et al., used YOLO for semantic segmentation of freight defects, achieving an accuracy of 57.4%. Authors in , used modified AlexNet\nand VGG for semantic segmentation of rail surfaces, achieving an accuracy of 90%.\ndefects that occur within specific regions or structures in the image, such as cracks orTransfer learning, a technique where a pre-trained model is used as a starting point for a new task, has also been applied to defect detection in railway components . Transferfine-tune on a smaller dataset . However, this approach reduces the risk of\noverfitting and allows the model to learn features from a larger, more diverse dataset.\nSantur et al. used ResNet50 transfer learning for rail inspection, achieving 94%\naccuracy in detecting surface defects. The authors in used transfer learning with ten CNN architectures (e.g., VGG-19, ResNet50, GoogleNet, etc.) for squat detection,\nachieving an accuracy range of 81.6%-91.89%. Anwar et al., used modified YOLOv4\nwith transfer learning for the detection of faulty valves, achieving an accuracy range of\n92.3%-96.3%. Chen et al. , used VGG and YOLO with transfer learning for fastenerFine-tuning can also be useful in railway defect detection for adjusting pre-trained models to better fit specific railway datasets. For example, a pre-trained CNN model can\nbe fine-tuned on a dataset of railway images containing different types of defects to learn the specific patterns and features of each defect. By fine-tuning a pre-trained model, it\naccuracy in detecting railway defect. Transfer learning involves keepingthe pre-trained weights and modifying only the final layers, while fine-tuningoutputs of multiple CNN models. For example, an ensemble of CNN models can be used to detect different types of railway defects such as rail cracks, joint defects,\nand wheel defects. Each CNN model can be trained on a specific subset of railway defect images, and the ensemble of models can provide more accurate and robustrelies on CNN-based techniques. Different data sources and data sizes are used to train and validate models, including camera-mounted vehicles, line scan cameras,\nand recordings over a track. Data preprocessing techniques such as resizing, noise\nreduc-tion, segmentation, and data augmentation have been commonly used to improve the quality and quantity of the data. However, there are following issues in- Backpropagation in the traditional approach is complex and time-consuming as itdepends on a trial and error approach to determine the appropriate parameters.- There is still a scarcity of suitable large datasets for heavy freight defect classifi\ncation. Training a defect classifier with new samples often suffers from overfitting- Although transfer learning and fine-tuning are good candidate solutions for sub duing the cost and complexity of backpropagation with limited data, the use of a for a specific classification problem and unable to handle unseen images.### 3\nMethodologyIn this section, we detail the architecture for the proposed reusable defect detection in railway. We choose Transfer learning and Ensemble Learning as the fundamental\nclassifier requires an accurate, fast, and esily modifiable model . In this context,\nthe inte-gration of fine-tuned CNNs could further improve the efficiency of defect detection systems. In particular, the aim of the proposed approach is to alleviate thewell as to ensure consistent performance for new and moderate sample sizes.Let us consider D as the dataset containing rail and wheel defect images. Ini-tially,\nwe need to train a set of n fine-tuned CNN models, denoted as M = {CN N1, CN N2,Each CNN model CN Ni is initialized with pre-trained weights wi obtained from\npre-trained CNNs, such as VGG19, RESNET50, and MobileNetV2. The fine-tuning\nprocess adapts the models to the defect detection task using the dataset D,Then, the predictions of the fine-tuned models are combined using an ensembling function f(w), which calculates the weighted average of the individual modelTo give more weight to models with lower loss values, the weights wi [∗] are selectedwhere the relationship between the weight is reciprocal to the loss value.\nAfter the optimal weights wi [∗] that maximize the accuracy of the ensemble modelwhere Acc(·) represents the accuracy metric, and λ is a parameter controllingAfter training the ensembled fine-tuned CNN model fens for a certain number of\nepochs, we evaluate the performance of the models on a validation set. Thewhere Ltrain denotes the training loss and Lval denotes the validation loss. θ represents the model parameters, θt and θt+1 are the model parameters at\nconsecutive epochs, and ϵ is a threshold that determines the acceptable change in the validation loss. The closer the value of ϵ is to 0 over a time period of tn − t,\nwhere tn − t repre-sents a large positive integer, the more consistent the model.This indicates that as the time period tn − t approaches infinity, the value of ϵ approaches 0, indicating a higher level of consistency in the model’s performance. In\nother words, the smaller the value of ϵ and the longer the time period considered, the more consistency is demonstrated by the model. By solving this optimization problem,\nconsistent performance on the validation set, indicating its robustness and reliability.and wheels. To identify defects in these components, multiple CNNs can be trained on a dataset of rail and wheel defect images, which can create a set of pre-trained CNN\nmodels. To ensure diversity among the models, each CNN can select training sets\nrandomly from the dataset using different hyperparameters, architectures, or data preprocessing techniques. Finally, the resulting models can be reused in a transferensembled approach. The diversity among the pre-trained models ensures that thetransfer-ensembled model can achieve consistent performance across various scenarios. Therefore, the proposed model can serve as a reusable tool for defect\nclassification tasks in railway inspection systems. The proposed system architecture for the reusable AI-enabled defect detection is illustrated in Figure 1. A brief- The architecture includes fine-tuned models fine-tuned CNN models (CN N1, CNN2, ·CN Nn), providing transferred knowledge (w1, w2, ·wn) of exist-ing neural- Then the models are then concatenated by ensembling w = (w1, w2, ·wn) using- The ensembling function of the predictions with the combined best accuracy atthe lowest loss. For example, if three different NN models classify images with\n80%, 84%, and 86% accuracy respectively, then an ensemble of these three\nmodels can provide, for example, 88% accuracy. The selection criteria are usuallyThe type of defects varies in size, shape, and texture; and the ensemble technique provides similar accuracy by combining the probability score predicted by multi-ple\nNN. The detail process of the architecture is detailed in the following section. TheWe adopted the fine-tuning approach for extracting parameters of the pre-trained\nCNN models with rail defects. For example, VGG-19 is a CNN of 19 layers and trained with a huge amount of colored image samples from the Imagenet database.\nThe layers of a pre-trained network are then modified to produce fine-tuned network for re-training the network with new training samples and labels. So that, the\nnetwork can be re-trained with new training samples and labels. This approach of\nscratch with few samples. Because to train a CNN model from the beginning- an\nrecognize image features and reduce the dimensionality of the image array.\nmodel. A good illustration of such a case is the Canadian CPR Dataset. Because type to train a multi-defect classifier. The fine-tuned model was therefore adopted to\ntrain a new network with pre-trained weights of an existing high-performance model.\nIn Figure 2, the process of fine-tuning an existing network to reuse it for a new1. Remove the input layer of CN Ni and add a convolutional layer Convti for the2. Copy and freeze all the convolutional layers until the output layers (Convi\nConvo−1). These are the layers containing pre-trained weights w that we might\nfor a target dataset. The freezing of layers can be presented as Equation:where Convj [(t)] denotes the j-th convolutional layer at training step t.3. The convolutional layers are frozen in the transfer learned neural network to avoidthe risk of losing the ”good features” that have been adopted from the existing network by forward propagating the weights. The forward propagation through thewhere σ represents the activation function and · denotes the convolution operation.4. Finally, remove the output layer of CN Ni and add a new output layer Convto asper the label (e.g., defect or normal) and number of outputs (e.g., 2) of the target defect dataset. The target output layer utilizes the learned weights w to learn\npatterns but is trained with new data. If n = 3, the visual representation of three\npre-trained CNN models connected to an ensemble layer based on their lowestnew deep networks with new data, we proposed lifetime modeling in a previous\nresearch study . The idea behind lifetime modeling is that transfer knowledge\ncan be used to classify new tasks. This comes into play when the model’s deployment environment is altered, and the feature or data subspace changes fromapproach, the randomly varied features (e.g., size, shape, and texture) of data (e.g.,\nimage of defective parts) pose the bottleneck issue. Precisely, depending on a single backbone network has a risk of significant loss and lower performance, in case the selected pre-trained network is unable to handle samples having randomly changed features. Therefore in this study, we propose the ensembling of multiple transfer learnedmodels to reduce the risk of total failure with a single network. The procedure of\nensembling fine-tuned models is illustrated in Algorithm 1. The steps for- A fine tune model is selected and the shape of this model is compared to thedefined shape to determine whether the fine-tuned model can be included in the- Step 1-2 is repeated for a finite number of times n; where n is the number of- The prediction by the model with minimum loss is selected as the final decisionThe time complexity of Algorithm 1 is influenced by various factors, including the number of fine-tuned models (M), the complexity of the loss function (L), the size of\nthe input data (D), the number of selected models (N), the complexity of the prediction function (P ), and the size(e.g., shape) of the input (I). Considering the\nabove steps, the overall time complexity of the algorithm can be approximated asBy simplifying, we can represent the time complexity as Equation (12).To explain the complexity, the initialization step of the algorithm has a constant time complexity, which is theoretically considered efficient. The model selection step\nhas a linear time complexity of O(M), where M represents the number of fine-tuned models. If M is finite and optimally small, the impact on the overall complexity is\nminimal. Therefore, the number of models should be selected optimally. Similar### 4\nDataWe trained the model using the Canadian Pacific Railway (CPR) dataset to train the defect classifier. The dataset contains 3000 images of railway parts, among which\n1000 images belong to the defect group, and 2000 images belong to the normal\ngroup. The dataset includes different views of the images, including the top view,\nbottom view, and a side view to better define the defective status of the parts.The raw dataset has 404 unique labels, which means we do not have enough images per label. So, we sampled the data based on the parts label. For instance,Verify, etc. were all considered under Broken Flange defect group. However, theIn this study, we performed two-class classification with the CPR dataset to show the effectiveness of our proposed model in both cases. Some examples from\nthe dataset are illustrated in Figure 4. For the binary classification, we considered the parent class defect and normal to mitigate the trade-off between sample size\nand class size. In this way, we got 1000 defect images and 2000 normal images.\nWe split the dataset into 60% training-25% and 25% testing datasets following the\nstate-of-the-art in the field of deep learning. The findings from the binary classification can also contribute to the subsequent multi-class classification.### 5\nExperiment and Result AnalysisIn this section, we detail the data, empirical analysis, and comparative analysis of the proposed and existing models. The overview of the three different experiments\nconducted in this study is tabulated inTable 2. Here, training parameters have beenWe employed a powerful configuration to ensure efficient and accurate computations while training the CNN models. The processing power was provided by an\nprocess-ing. To handle complex graphics-related tasks, we utilized the NVIDIA\nGeForce RTX 2080 GPU, which deliveres high-performance computing for deep learning algorithms. The machine was equipped with a substantial 64 GB of RAM,\nproviding sufficient memory to handle complex model architectures. Running on a Architecture augmentation layer MobileNetV3, and three fine-tuned modRESNET50 elsTrainable 183,682 parameters Frozen layers till Frozen fine-tuned layLayers dense layer ers Training Batch size: 32, Epochs: Batch size: 32, Learning rate schedParameters 50\nPerformance Accuracy, Loss, Batch Accuracy, Loss Accuracy, Loss, PreciMetrics Prediction sion, RecallTo classify a defected and non-defected images, the predictions of the finetuned models are combined using the sigmoid function f(·) to obtain the probabilitywhere yˆ represents the predicted probability for the positive class, and w1, w2, . . .,After obtaining the predicted probability, a threshold is applied to determine the final class label. If the predicted probability is above the threshold, the input image\nis classified as the positive class (defect); otherwise, it is classified as the negativeDuring the training process, the parameters wi of each model are optimized towhere Lb calculates the binary cross-entropy loss between the predictedissues. To evaluate the impact of using an augmented CNN model, we initially applied a data augmentation layer to a baseline CNN model and compared the performance. In\nthis section, we present the experiment and outcomes of this evaluation.In the previous section, it was noted that the raw dataset used in this study consisted of 81 unique classes, which can pose a challenge in developing accurate\npredictive models for railway assets due to their inherent heterogeneity. Manual\nfeature extraction or data preprocessing can be time-consuming and may not be practical for large datasets. To address this challenge, a CNN classifier with a sequential augmentation layer was implemented. The augmentation layer randomlyAn example of the augmentation layer task is illustrated in Figure 5. To standardize\nthe pixel value, the layer resizes the images to a consistent shape at 255 and then rescales them at (1./255). To further augment the data, horizontal and vertical random flips and random rotation at 0. were applied. Conventional layers with a 3 x 3 spatial size kernel, a stride size of 1, and a padding of 2 were used. Max pooling with a kernel size of\nLinear Unit (Relu) activation function was used for normalization. The model had\n183,682 trainable parameters, which were optimized through several rounds of\nparameter tuning. A batch size of 32 and 50 epochs was used for training, with a split ofTo evaluate the impact of adding the augmented layer, we compared the performance of the model with and without the augmented layer. It is evident from Figure 7, that the\nscore. As shown in Figure 6, the training accuracy improved by nearly 20% after adding\nthe augmented layer. Similarly, the validation accuracy increased from80% to 90% and both training and validation loss decreased. These improvementsOverall, the prediction confidence score was good, as Figure 8 demonstrates through-out the epochs. We investigated the reason for the jump in the validationmanually. We obtained the feature of these two images and found that the feature pixels quite resemble each other. Furthermore, By plotting the correlation matrix as\na heatmap in Figure 10, we can observe patterns and relationships among the\nfeatures of two resembled defective and normal images. Here, areas of high\ncorrelation (brighter colors) indicate a strong correlation between those features. On the contrary, areas of low correlation (darker colors) suggest a weaker relationship or independence between the features. It is evi-dent from the heatmaps of the images that they have similar feature patterns. This implies that the regions of the\nimages share common patterns or characteristics for the defect and normal images.In summary, although the data augmentation improved the model’s accuracy, it was not able to handle the fluctuations in performance due to the overfitting issue.\nTherefore, we applied fine-tuning in the next phase to further improve the model’swas compared in this study. Transfer learning was utilized as a method to enhance the performance of the models. In this section, we present the experiment details ofThe models are pre-trained on ImageNet database and accept 224X224 images as\ninput. Therefore, we resized the training images to fulfill this requirement. We freeze the layers till the dense layer by setting the trainable layer parameter to false.\nInstead of freezing all layers, a few layers could be trained. However, due to the moderate sample size, it was tedious to determine the exact layers to be trained.Figure 11 shows the comparison of the classification performance of individual models on the training and validation sets. The results demonstrated in Figure 8,than the augmented CNN model which required approximately 40 epochs to reachMoreover, the fine-tuned models exhibited reduced fluctuation after the initial\nepochs, and the gap between validation and training performance decreased.\nSpecifi-cally, for the RESNET50 model, there was a reduction in fluctuation and anAt some points, the training and validation curves intersected, indicating successful mitigation of the overfitting issue at those epochs. This suggests that transfer learningmodels as well as improving the stability of the models during training.However, the performance evaluation of different fine-tuned models on the same data in this study revealed a variation while training. For VGG, the minimum\nvali-dation loss of 0.0067 was achieved during the first epoch, while for MobileNet,\nit was obtained during the third epoch with a value of 0.0055, and for ResNet, it was reached during the sixth epoch with a validation loss of 0.0103. Interestingly, the\nvalidation accuracy for VGG was 0. during the minimum validation loss, while foraccuracy, the MobileNet model showed the least loss with the lowest accuracy. As a result, it is challenging to select a single model that performs the best. The findings of\nDL models. To address this requirement, we proposed an ensemble model, which aims to obtain the best potential models from a single model. The performance of thethe images were resized into 224X224 before extracting the heatmap. The Feature\nIndex represents the position of the features in the correlation matrix.In order to obtain the proposed reusable model, we combined the previously finetuned VGG19, RESNET50, and MobileNetV3 CNN models into an ensemble\nmodel. This section provides a detailed account of the experiment setup andtrain-ing and validation sets. X-axis represents epochs, and Y-axis represents the accuracy. train ACC = accuracy curve of the training set, val ACC = accuracy curve of the validation set, train loss = loss curve of the training set, and val loss = lossTo obtain the ensemble model, the three models were concatenated as linear models. For selecting prediction, the minimum loss was obtained. Since multiple\nfine-tuned models had good performance in different epochs, the number of epochs was increased to 20, and a learning-rate scheduler starting from 0. was used toThe findings of the evaluation of loss and accuracy graphs are shown in Figure 12.\nFrom the graphs, it is evident that after the initial epochs, the loss and accuracy levelsreached an acceptable point and remained constant at almost 0.0001 validationThe bar diagram Figure 13, presents precision, recall, and F1-score for the\nindivid-ual models, including MobileNetV3, ResNet50, VGG-19, and the proposed ensemble model. It is observed that the proposed ensemble model has the highest\nF1-score of 0.98, followed closely by MobileNetV3 and VGG-19 with F1-scores of\n0. and 0. respectively. ResNet50 has the lowest F1-score of 0.85. The reasoneliminates the weaknesses. Comparitavely, ResNet50 may have lower performance\ndue to its architecture and complexity, which may have led to overfitting.In a nutshell, the proposed ensemble model showed comparatively better results for the classification task, while the individual models also demonstrated reasonable\nperformance. Subsequently, the challenge of achieving higher accuracy and lower loss from the same model was addressed through the ensembling of fine-tuned models. Thisapproach effectively leverages the strengths of each model, resulting in a moreIn this section, we present a comparison of the performance between our proposed model and other models used in various rail defect classification studies. While making\nthe comparison, we encountered two challenges. Firstly, the majority of studies have trained their models using in-house and private datasets. One of the reasons behind this defect classification. Secondly, the selection of performance metrics has not been consistent across different studies. Most studies have focused solely on test accuracy\nand few have considered other essential metrics such as F1-score, precision, and recall. To address these challenges and provide we categorized the existing work into three groups based on the type of the models used. Table 3 summarizes the total data1000 1DCNN and LSTM Dataset-2: Recall-0.9427, Precision-0.9176, F1-score 0.9300\nPrecision: 0.99, Recall: 0.98, F1-score: 0.98, Test-Accuracy:99%Faghih et al. and Jamshidi et al. employed Deep CNN (DCNN) models,\nachieving accuracies of 92% and 96.9%. While these models demonstrate the\neffective-ness of DCNNs in rail defect classification tasks, they may face limitations in dealing with complex and diverse defect types. Because if the sample size for\ntraining a new defect classifier is not enough, then a DCNN model can not be reused. Therefore, The performance could be improved by incorporating transfer\nlearning techniques. In our proposed model we handled this and obtained betterYanan et al. utilized YOLOv3, while Liang et al. employed YOLO and\nYOLO+MobileNet models. These models achieved accuracies ranging from 57.4% to\n97%. The relatively lower accuracy of YOLO in could be attributed to the limited\ndataset size (120 images). Although YOLO is a popular choice due to its accuracy in real-time object detection, it requires manually labeled bounding box samples totrain the model. Authors may have mostly used lower sample size for training YOLO defect classifier, due to its labor-intensive and time-consuming data preparation\nstep. Another reason could be the unavailability of the data. Surprisingly, the\nauthors in could obtain only 87% accuracy even though they employed a large concatenating three bot-tleneck modules. By contrast, in our proposed model we performed the concatenation of the model based on the lowest loss. So that, theKim et al. utilized modified AlexNet and VGG models, achieving an accuracy of\n90% on their dataset. Santur et al. employed transfer learning with ResNet50,\nachieving an accuracy of 94%. Similarly, James et al. utilized RESNET and\nDenseNET models, achieving an accuracy of 90%. Passos et al. utilized 10\npre-trained CNN models and achieved accuracies ranging from 81.6% to 91.89%\nfor defect classification. While these models perform reasonably well, ensembling techniques, such as combining predictions from multiple models or utilizing an\nensemble of dif-ferent architectures, can help improve the overall performance by\ncapturing diverse representations and reducing the impact of model biases.Comparing to existing approaches in and , our proposed model outperforms\nin terms of precision, recall, and F1-score. The higher precision at 0. indicates only\n1% rate of misclassifying non-defective samples as defects. The higher recall at 0.\ndemonstrates the model’s capability to correctly identify actual defects, which is a crucial\nmeasure in the context of rail defect diagnosis. The F1-score is also at 0.\nmodel. As most of the studies have trained the CNN models for in-house dataset the test accuracy is good (above 90%) for several studies. However, our proposed model\nnot only demonstrated comparative better test accuracy (at 99%) but also showed\ndecent performance for other accuracy measures. Moreover,we have obtainedcapability of three CNN models- namely, RESNET50, VGG19, and MobileNetV3. To be specific, RESNET50 allows capturing of intricate features and patterns within the rail\ndefect images. VGG19 enables the extraction of high-level features. MobileNetV3, on the other hand, is a lightweight and efficient architecture, facilitating faster infer-ence and\nensuring higher accuracy. Therefore, if a new portion of samples does not fit a specific### 6\nLimitations and Future WorkThe proposed work has some limitations that need to be addressed. The model is evaluated by performing binary classification, which means that it can accurately distinguish between normal and defective parts. However, we have evaluated the performance of the model in terms of different accuracy measures and obtained high andconsistent accuracy. Further research is needed to investigate the effectiveness of the model in identifying various types of defects or locating the precise defect location.predictions, it can be computationally expensive and time-consuming. Visual transformers (ViT) , on the other hand, ViT is a type of DL model that has recently\nshown remarkable performance on various CV tasks, including image classification and object detection. They have the ability to capture global spatial information from\nan image and attend to specific regions of interest, making them highly effective for\ncom-plex visual recognition tasks. Therefore, for further research, visual transformers, as a type of DL model, can be explored as an alternative approach to\nimprove the speed along with the accuracy of the railway defect detection system.### 7\nConclusionIn conclusion, we have presented an approach for railway defect detection combining transfer learning and an efficient reusable model. We demonstrated that the ensem-bling and fine-tuning of transfer learning with VGG-19, MobileNetV3, and ResNet-50 models achieve high accuracy at different epochs. Our proposed model provided 99% accuracy reduced overfitting, and exhibited stable performance after a certain epoch. Overall, our proposed approach contributes to the development of a more efficient and effective method for railway defect detection, which can potentially improve railway safety and reliability. Taking the linear complexity of\nmodel speed in consideration, the use of a visual transformer model can be a further extension of ensembled trans-fer learning to speed up training without sacrificing\naccuracy. Therefore, in future work, we aim to investigate the effectiveness of visual### DeclarationThe methods presented in this paper are highly demanded in developing AIenabled digital twin for Industry, particularly for application domains that requires- Rahatara Ferdousi: Conceptualization, Methodology, Writing - Original DraftWe have signed a business agreement with the data provider. We have consent forThe datasets analyzed during the current study are not publicly available. Due to the terms of the business agreement, we cannot disclose the data for public access", "year": "2000"}}
